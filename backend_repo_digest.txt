Repository Source Code Contents
Generated on: Thu Aug 14 08:49:01 IST 2025
----------------------------------------
File: ./domains/data_science/config.py
----------------------------------------
# ============================================================================
# File: domains/data_science/config.py
# Data Science domain configuration
# ============================================================================

from typing import Dict, Any, List
from models.module_models import EvaluationType

class DataScienceConfig:
    """Configuration for Data Science domain learning"""
    
    # Domain identifier
    DOMAIN_ID = "data_science"
    DOMAIN_NAME = "Data Science"
    
    # Hierarchy configuration
    HIERARCHY = {
        "levels": ["topic", "module"],  # Only Topic -> Module for now
        "show_levels": ["topic", "module"],  # What to show in navigation
        "expandable_levels": ["topic"],  # Which levels can be expanded/collapsed
    }
    
    # Navigation configuration
    NAVIGATION = {
        "default_expanded_topics": 1,  # Only first topic expanded by default
        "show_progress_indicators": True,
        "show_estimated_time": True,
        "auto_expand_on_select": True
    }
    
    # Module generation defaults
    MODULE_GENERATION = {
        "default_modules_per_topic": 4,  # Suggested number of modules per topic
        "min_modules_per_topic": 2,
        "max_modules_per_topic": 8,
        "default_module_hours": 2.0,  # Default hours per module if not specified
        "evaluation_types": [
            EvaluationType.CODING_EXERCISE,
            EvaluationType.QUIZ,
            EvaluationType.MIXED
        ]
    }
    
    # Coach configuration
    COACH = {
        "width_percentage": 25,  # 25% of screen width
        "navigation_section_height": "50%",  # Top half for navigation
        "motivation_section_height": "50%",  # Bottom half for motivation
        "show_motivation_messages": True,
        "motivation_update_interval": 300  # seconds
    }
    
    # Sidebar layout configuration
    SIDEBAR_LAYOUT = {
        "hierarchy": [
            {
                "level": "topic",
                "expandable": True,
                "show_progress": True,
                "show_estimated_time": True,
                "default_expanded": "first_only"  # "first_only", "all", "none"
            },
            {
                "level": "module", 
                "expandable": False,
                "show_progress": True,
                "show_estimated_time": True,
                "selectable": True,
                "show_under_parent": True
            }
        ]
    }
    
    # Motivation messages for different progress stages
    MOTIVATION_MESSAGES = {
        "start": [
            "🚀 Ready to dive into your first topic? Let's start building your data science expertise!",
            "💪 Your personalized learning journey begins now. Every expert was once a beginner!",
            "🎯 Focus on one module at a time - consistency beats intensity!"
        ],
        "progress": [
            "🔥 Great momentum! You're making real progress toward your goals.",
            "📈 Each module completed brings you closer to data science mastery!",
            "⚡ Keep going! Your future self will thank you for this dedication.",
            "🧠 Your brain is building new neural pathways with every concept you learn!"
        ],
        "completion": [
            "🎉 Module completed! Take a moment to appreciate your progress.",
            "✅ Another step closer to your data science goals. Well done!",
            "🏆 Excellent work! Ready for the next challenge?"
        ]
    }
    
    @classmethod
    def get_config(cls) -> Dict[str, Any]:
        """Get complete configuration as dictionary"""
        return {
            "domain_id": cls.DOMAIN_ID,
            "domain_name": cls.DOMAIN_NAME,
            "hierarchy": cls.HIERARCHY,
            "navigation": cls.NAVIGATION,
            "module_generation": cls.MODULE_GENERATION,
            "coach": cls.COACH,
            "sidebar_layout": cls.SIDEBAR_LAYOUT,
            "motivation_messages": cls.MOTIVATION_MESSAGES
        }
    
    @classmethod
    def get_sidebar_hierarchy(cls) -> List[Dict[str, Any]]:
        """Get sidebar hierarchy configuration"""
        return cls.SIDEBAR_LAYOUT["hierarchy"]
    
    @classmethod
    def get_evaluation_types(cls) -> List[EvaluationType]:
        """Get supported evaluation types for this domain"""
        return cls.MODULE_GENERATION["evaluation_types"]
----------------------------------------
File: ./domains/data_science/prompts/toc_prompts.py
----------------------------------------
# ============================================================================
# File: domains/data_science/prompts/toc_prompts.py
# Generic prompt that passes user preferences to LLM without bias
# ============================================================================

# Single generic prompt that lets LLM decide based on user preferences
DATA_SCIENCE_TOC_PROMPT = """
Create a comprehensive Data Science curriculum Table of Contents based on the user's specific preferences and background.

User's Complete Profile:
{user_preferences}

Instructions:
1. Analyze the user's goals, experience level, learning style, time constraints, and technical background
2. Design a curriculum that EXACTLY matches their stated preferences
3. If they want career-focused content, emphasize job-ready skills
4. If they want hands-on learning, prioritize practical projects over theory
5. If they're a beginner, start with fundamentals; if advanced, focus on sophisticated topics
6. Respect their time constraints and daily commitment preferences
7. Build on their existing technical skills (programming, math, domain knowledge)

Generate topics that cover relevant areas of data science:
- Programming and tools
- Mathematics and statistics  
- Data manipulation and analysis
- Machine learning
- Data visualization
- Specialized domains (NLP, computer vision, etc.)
- Industry applications
- Portfolio/project work

Structure the curriculum to:
- Have logical progression and clear prerequisites
- Include realistic time estimates based on their availability
- Mark essential vs optional topics based on their goals
- Provide detailed subtopics that show learning value
- Match the complexity to their experience level

Let the user's stated preferences guide ALL decisions about:
- Depth vs breadth
- Theory vs practice ratio
- Beginner vs advanced content
- Career vs academic focus
- Time allocation per topic

Domain: data_science
"""

def get_toc_prompt(user_preferences: dict) -> str:
    """
    Format the generic prompt with user preferences
    No selection logic - just pass everything to LLM
    """
    # Convert user preferences to a readable format for the LLM
    formatted_preferences = []
    
    for key, value in user_preferences.items():
        if isinstance(value, list):
            formatted_preferences.append(f"- {key.replace('_', ' ').title()}: {', '.join(value) if value else 'None specified'}")
        else:
            formatted_preferences.append(f"- {key.replace('_', ' ').title()}: {value}")
    
    preferences_text = '\n'.join(formatted_preferences)
    
    return DATA_SCIENCE_TOC_PROMPT.format(user_preferences=preferences_text)
----------------------------------------
File: ./domains/data_science/prompts/module_prompts.py
----------------------------------------
# ============================================================================
# File: domains/data_science/prompts/module_prompts.py
# Data Science specific prompts for module generation
# ============================================================================

DATA_SCIENCE_MODULE_PROMPT = """
You are an expert Data Science curriculum designer. Break down the following topic into detailed learning modules.

Topic Information:
- Topic Name: {topic_name}
- Topic Description: {topic_description}
- Estimated Hours: {topic_hours}
- Difficulty Level: {topic_difficulty}
- Prerequisites: {topic_prerequisites}

User Context:
{user_preferences}

Instructions:
1. Create 2-5 modules that logically break down this topic
2. Each module should be max 30 min of focussed learning
3. Modules should build on each other with clear progression
4. Include practical coding exercises and theoretical understanding
5. Match the user's experience level and learning preferences
6. Ensure modules align with their stated goals

For each module, specify:
- Clear learning objectives (what they'll be able to do after completion)
- Appropriate evaluation method (coding exercises, quizzes, or mixed)
- Logical ordering and dependencies
- Realistic time estimates

Topic Breakdown Guidelines:
- Start with foundational concepts if the user is a beginner
- Include hands-on practice for practical learners
- Build complexity gradually
- End with application or integration exercises
- Consider real-world use cases aligned with their goals

Generate modules that create a coherent learning experience where each module prepares the learner for the next while building practical skills.
"""

def get_module_prompt(topic_data: dict, user_preferences: dict) -> str:
    """
    Format the module generation prompt with topic and user data
    
    Args:
        topic_data: Dictionary containing topic information
        user_preferences: User preferences from onboarding
        
    Returns:
        Formatted prompt string
    """
    
    # Format user preferences for the prompt
    preferences_text = []
    
    if user_preferences:
        for key, value in user_preferences.items():
            if isinstance(value, list):
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {', '.join(value) if value else 'None specified'}")
            else:
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {value}")
    
    user_context = '\n'.join(preferences_text) if preferences_text else "No specific user preferences provided"
    
    return DATA_SCIENCE_MODULE_PROMPT.format(
        topic_name=topic_data.get('name', 'Unknown Topic'),
        topic_description=topic_data.get('description', 'No description provided'),
        topic_hours=topic_data.get('estimated_hours', 'Not specified'),
        topic_difficulty=topic_data.get('difficulty', 'Not specified'),
        topic_prerequisites=', '.join(topic_data.get('prerequisites', [])) or 'None',
        user_preferences=user_context
    )
----------------------------------------
File: ./domains/data_science/prompts/concept_prompts.py
----------------------------------------
# ============================================================================
# File: domains/data_science/prompts/concept_prompts.py
# Data Science specific prompts for concept generation
# ============================================================================

CONCEPT_GENERATION_PROMPT = """
You are an expert Data Science instructor. Break down the following module into detailed learning concepts.

Module Information:
- Module Name: {module_name}
- Module Description: {module_description}
- Total Estimated Time: {total_estimated_minutes} minutes
- Learning Objectives: {learning_objectives}
- Evaluation Type: {evaluation_type}

User Context:
{user_preferences}

Instructions:
1. Break this module into 3-6 concepts, each taking 10-20 minutes to complete
2. Each concept should be focused on a single, digestible topic
3. Concepts should build on each other with clear progression
4. Match the user's experience level and learning preferences
5. Include practical examples relevant to their goals

For each concept, provide:
- Clear name and description
- Specific learning objectives 
- Estimated time in minutes
- Logical ordering within the module

Concept Breakdown Guidelines:
- Start with foundational understanding if the user is a beginner
- Include hands-on elements for practical learners
- Build complexity gradually across concepts
- End with application or integration exercises
- Consider real-world use cases aligned with their goals

Focus on creating concepts that prepare learners for the module's evaluation type: {evaluation_type}

Generate concepts that create a coherent learning experience where each concept builds toward mastering the module objectives.
"""

CONCEPT_CONTENT_PROMPT = """
You are an expert Data Science instructor. Generate detailed learning content for the following concept.

Concept Information:
- Concept Name: {concept_name}
- Concept Description: {concept_description}
- Estimated Time: {estimated_minutes} minutes
- Learning Objectives: {learning_objectives}
- Module Context: {module_name}

User Context:
{user_preferences}

Content Requirements:
1. Generate content as markdown that can be displayed on a web page
2. Break content into 3-5 content blocks, each taking 2-4 minutes to read
3. Include practical code examples using Python for data science
4. Use clear headings, bullet points, and code blocks for readability
5. Match the user's experience level - avoid concepts they already know
6. Include "Try This" exercises within the content

Content Structure:
- Introduction block: What they'll learn and why it matters
- Core explanation blocks: Step-by-step breakdown of the concept
- Practical example block: Real code example with explanation
- Summary block: Key takeaways and next steps

Formatting Guidelines:
- Use ## for main headings, ### for subheadings
- Include code blocks with ```python
- Use bullet points for key concepts
- Include callout boxes with > for important notes
- Keep paragraphs concise (2-3 sentences max)

Make the content engaging and practical for someone pursuing: {user_goal}
"""

CONCEPT_NOTES_PROMPT = """
You are an expert Data Science instructor. Generate concise study notes for the following concept.

Concept Information:
- Concept Name: {concept_name}
- Learning Objectives: {learning_objectives}
- Module Context: {module_name}

User Context:
{user_preferences}

Generate comprehensive study notes that include:

1. **Key Concepts** (3-5 bullet points)
   - Most important ideas from this concept
   - Definitions of critical terms

2. **Essential Formulas/Code Patterns** 
   - Important mathematical formulas (if applicable)
   - Key code snippets or patterns
   - Syntax reminders

3. **Quick Reference**
   - When to use this concept
   - Common parameters or options
   - Typical use cases

4. **Memory Aids**
   - Mnemonics or mental models
   - Visual analogies
   - Connection to previous concepts

5. **Common Mistakes to Avoid**
   - Typical errors beginners make
   - Debug tips

Format as clean markdown with clear sections. Keep it concise but comprehensive - should serve as a quick reference sheet they can return to later.

Target length: 200-400 words total.
"""

CONCEPT_EVALUATION_PROMPT = """
You are an expert Data Science instructor. Generate evaluation content for the following concept.

Concept Information:
- Concept Name: {concept_name}
- Learning Objectives: {learning_objectives}
- Evaluation Type: {evaluation_type}
- Module Context: {module_name}

User Context:
{user_preferences}

Based on the evaluation type, generate appropriate assessment:

For CODING_EXERCISE:
- Create 2-3 progressive coding challenges
- Start with a simple warm-up exercise
- Include a more complex application problem
- Provide starter code and clear instructions
- Include test cases and expected outputs

For QUIZ:
- Create 5-7 multiple choice questions
- Include questions at different difficulty levels
- Test both conceptual understanding and practical application
- Provide clear explanations for correct answers

For MIXED:
- Combine 1-2 coding exercises with 3-4 quiz questions
- Ensure both theory and practice are assessed

Evaluation Guidelines:
- Match the user's experience level
- Test the specific learning objectives of this concept
- Include realistic scenarios from their goal domain
- Provide immediate feedback opportunities
- Make exercises engaging and relevant

Format as structured JSON with clear sections for each type of evaluation content.
"""

def get_concept_generation_prompt(module_data: dict, user_preferences: dict) -> str:
    """
    Format the concept generation prompt with module and user data
    """
    preferences_text = []
    
    if user_preferences:
        for key, value in user_preferences.items():
            if isinstance(value, list):
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {', '.join(value) if value else 'None specified'}")
            else:
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {value}")
    
    user_context = '\n'.join(preferences_text) if preferences_text else "No specific user preferences provided"
    
    return CONCEPT_GENERATION_PROMPT.format(
        module_name=module_data.get('name', 'Unknown Module'),
        module_description=module_data.get('description', 'No description provided'),
        total_estimated_minutes=int((module_data.get('estimated_hours', 2) * 60)),
        learning_objectives=', '.join(module_data.get('learning_objectives', [])) or 'Not specified',
        evaluation_type=module_data.get('evaluation_type', 'mixed'),
        user_preferences=user_context
    )

def get_concept_content_prompt(concept_data: dict, module_data: dict, user_preferences: dict) -> str:
    """
    Format the concept content generation prompt
    """
    preferences_text = []
    
    if user_preferences:
        for key, value in user_preferences.items():
            if isinstance(value, list):
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {', '.join(value) if value else 'None specified'}")
            else:
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {value}")
    
    user_context = '\n'.join(preferences_text) if preferences_text else "No specific user preferences provided"
    user_goal = user_preferences.get('goal', 'general learning')
    
    return CONCEPT_CONTENT_PROMPT.format(
        concept_name=concept_data.get('name', 'Unknown Concept'),
        concept_description=concept_data.get('description', 'No description provided'),
        estimated_minutes=int(concept_data.get('estimated_minutes', 15)),
        learning_objectives=', '.join(concept_data.get('learning_objectives', [])) or 'Not specified',
        module_name=module_data.get('name', 'Unknown Module'),
        user_preferences=user_context,
        user_goal=user_goal
    )

def get_concept_notes_prompt(concept_data: dict, module_data: dict, user_preferences: dict) -> str:
    """
    Format the concept notes generation prompt
    """
    preferences_text = []
    
    if user_preferences:
        for key, value in user_preferences.items():
            if isinstance(value, list):
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {', '.join(value) if value else 'None specified'}")
            else:
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {value}")
    
    user_context = '\n'.join(preferences_text) if preferences_text else "No specific user preferences provided"
    
    return CONCEPT_NOTES_PROMPT.format(
        concept_name=concept_data.get('name', 'Unknown Concept'),
        learning_objectives=', '.join(concept_data.get('learning_objectives', [])) or 'Not specified',
        module_name=module_data.get('name', 'Unknown Module'),
        user_preferences=user_context
    )

def get_concept_evaluation_prompt(concept_data: dict, module_data: dict, user_preferences: dict) -> str:
    """
    Format the concept evaluation generation prompt
    """
    preferences_text = []
    
    if user_preferences:
        for key, value in user_preferences.items():
            if isinstance(value, list):
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {', '.join(value) if value else 'None specified'}")
            else:
                preferences_text.append(f"- {key.replace('_', ' ').title()}: {value}")
    
    user_context = '\n'.join(preferences_text) if preferences_text else "No specific user preferences provided"
    
    return CONCEPT_EVALUATION_PROMPT.format(
        concept_name=concept_data.get('name', 'Unknown Concept'),
        learning_objectives=', '.join(concept_data.get('learning_objectives', [])) or 'Not specified',
        evaluation_type=concept_data.get('evaluation_type', 'mixed'),
        module_name=module_data.get('name', 'Unknown Module'),
        user_preferences=user_context
    )
----------------------------------------
File: ./models.py
----------------------------------------
# ============================================================================
# File: models.py (NEW FILE)
# Enhanced Pydantic models for onboarding data
# ============================================================================

from pydantic import BaseModel
from typing import Dict, Any, List, Optional
from enum import Enum

class LearnerLevel(str, Enum):
    COMPLETE_BEGINNER = "complete-beginner"
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"

class CourseStyle(str, Enum):
    HANDS_ON = "hands-on"
    BALANCED = "balanced"
    CONCEPT_HEAVY = "concept-heavy"

class TotalTime(str, Enum):
    FOUR_HOURS = "4-hours"
    ONE_TWO_WEEKS = "1-2-weeks"
    ONE_MONTH = "1-month"
    TWO_THREE_MONTHS = "2-3-months"

class DailyTime(str, Enum):
    THIRTY_MIN = "30-min"
    ONE_HOUR = "1-hour"
    TWO_THREE_HOURS = "2-3-hours"

class TechnicalBackground(BaseModel):
    programming: List[str] = []
    math: List[str] = []
    domain: List[str] = []

class OnboardingData(BaseModel):
    goal: Optional[str] = None
    learner_level_detailed: Optional[LearnerLevel] = None
    course_material_detailed: Optional[CourseStyle] = None
    total_time_detailed: Optional[TotalTime] = None
    daily_time_detailed: Optional[DailyTime] = None
    technical_background: Optional[TechnicalBackground] = None
----------------------------------------
File: ./models/toc_models.py
----------------------------------------
# ============================================================================
# File: models/toc_models.py
# Pydantic models for TOC and learning path structures
# ============================================================================

from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from enum import Enum

class DifficultyLevel(str, Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"

class TopicType(str, Enum):
    THEORETICAL = "theoretical"
    PRACTICAL = "practical"
    MIXED = "mixed"

class SubTopic(BaseModel):
    id: str = Field(..., description="Unique identifier for the subtopic")
    name: str = Field(..., description="Name of the subtopic")
    description: str = Field(..., description="Brief description of what this subtopic covers")
    estimated_hours: float = Field(..., description="Estimated time to complete in hours")
    difficulty: DifficultyLevel = Field(..., description="Difficulty level of this subtopic")
    prerequisites: List[str] = Field(default=[], description="List of prerequisite subtopic IDs")

class Topic(BaseModel):
    id: str = Field(..., description="Unique identifier for the topic")
    name: str = Field(..., description="Name of the topic")
    description: str = Field(..., description="Brief description of what this topic covers")
    estimated_hours: float = Field(..., description="Total estimated time for this topic in hours")
    difficulty: DifficultyLevel = Field(..., description="Overall difficulty level")
    topic_type: TopicType = Field(..., description="Type of topic (theoretical/practical/mixed)")
    subtopics: List[SubTopic] = Field(default=[], description="List of subtopics under this topic")
    prerequisites: List[str] = Field(default=[], description="List of prerequisite topic IDs")
    is_core: bool = Field(..., description="Whether this topic is core/essential for the domain")

class TableOfContents(BaseModel):
    domain: str = Field(..., description="The domain this TOC is for (e.g., 'data_science', 'cat_exam')")
    title: str = Field(..., description="Title of the course/curriculum")
    description: str = Field(..., description="Brief description of the overall curriculum")
    total_estimated_hours: float = Field(..., description="Total estimated time for all topics")
    topics: List[Topic] = Field(..., description="List of all topics in the curriculum")
    learning_path_suggestions: List[str] = Field(
        default=[], 
        description="Suggested topic IDs for different learning paths"
    )

class LearningPath(BaseModel):
    user_id: str = Field(..., description="User identifier")
    session_id: str = Field(..., description="Session identifier")
    domain: str = Field(..., description="Domain for this learning path")
    selected_topics: List[str] = Field(..., description="List of selected topic IDs")
    estimated_total_hours: float = Field(..., description="Total estimated hours for selected topics")
    created_at: str = Field(..., description="When this learning path was created")
    user_preferences: Optional[Dict[str, Any]] = Field(
        default=None, 
        description="User preferences from onboarding"
    )

# Response models for API endpoints
class TOCResponse(BaseModel):
    success: bool = Field(default=True)
    data: TableOfContents = Field(..., description="Generated table of contents")
    message: str = Field(default="TOC generated successfully")

class LearningPathResponse(BaseModel):
    success: bool = Field(default=True)
    data: LearningPath = Field(..., description="Created learning path")
    message: str = Field(default="Learning path created successfully")
----------------------------------------
File: ./models/module_models.py
----------------------------------------
# ============================================================================
# File: models/module_models.py
# Module models for the learning platform
# ============================================================================

from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from enum import Enum

class ModuleStatus(str, Enum):
    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"

class EvaluationType(str, Enum):
    CODING_EXERCISE = "coding_exercise"
    QUIZ = "quiz"
    PROJECT = "project"
    MIXED = "mixed"

class Module(BaseModel):
    id: str = Field(..., description="Unique identifier for the module")
    topic_id: str = Field(..., description="ID of the parent topic")
    name: str = Field(..., description="Name of the module")
    description: str = Field(..., description="Brief description of the module")
    estimated_hours: float = Field(..., description="Estimated time to complete in hours")
    learning_objectives: List[str] = Field(default=[], description="What learner will achieve")
    prerequisites: List[str] = Field(default=[], description="Prerequisites for this module")
    evaluation_type: EvaluationType = Field(..., description="Type of evaluation for this module")
    order: int = Field(..., description="Order within the topic")
    
class TopicWithModules(BaseModel):
    topic_id: str = Field(..., description="Topic identifier")
    topic_name: str = Field(..., description="Topic name")
    topic_description: str = Field(..., description="Topic description")
    modules: List[Module] = Field(..., description="List of modules for this topic")
    total_estimated_hours: float = Field(..., description="Total hours for all modules")
    
class ModuleGenerationRequest(BaseModel):
    session_id: str = Field(..., description="Session identifier")
    topic_id: str = Field(..., description="Topic ID to generate modules for")
    
class ModuleGenerationResponse(BaseModel):
    success: bool = Field(default=True)
    data: TopicWithModules = Field(..., description="Topic with generated modules")
    message: str = Field(default="Modules generated successfully")
----------------------------------------
File: ./models/concept_models.py
----------------------------------------
# ============================================================================
# File: models/concept_models.py
# Enhanced models for concept-level content generation
# ============================================================================

from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from enum import Enum
from models.module_models import EvaluationType

class ConceptStatus(str, Enum):
    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"

class ContentBlock(BaseModel):
    id: str = Field(..., description="Unique identifier for the content block")
    type: str = Field(..., description="Type of content block (text, code, exercise, etc.)")
    content: str = Field(..., description="Markdown content for the block")
    order: int = Field(..., description="Order within the concept")
    estimated_minutes: float = Field(default=2.0, description="Time to complete this block")

class Concept(BaseModel):
    id: str = Field(..., description="Unique identifier for the concept")
    module_id: str = Field(..., description="ID of the parent module")
    name: str = Field(..., description="Name of the concept")
    description: str = Field(..., description="Brief description of the concept")
    estimated_minutes: float = Field(..., description="Estimated time to complete in minutes")
    learning_objectives: List[str] = Field(default=[], description="What learner will achieve")
    content_blocks: List[ContentBlock] = Field(default=[], description="Content blocks for this concept")
    evaluation_type: Optional[EvaluationType] = Field(None, description="Type of evaluation")
    evaluation_content: Optional[str] = Field(None, description="Evaluation questions/exercises")
    notes_summary: Optional[str] = Field(None, description="Key points and formulas")
    order: int = Field(..., description="Order within the module")
    status: ConceptStatus = Field(default=ConceptStatus.NOT_STARTED, description="Completion status")

class ModuleWithConcepts(BaseModel):
    module_id: str = Field(..., description="Module identifier")
    module_name: str = Field(..., description="Module name")
    module_description: str = Field(..., description="Module description")
    topic_id: str = Field(..., description="Parent topic ID")
    concepts: List[Concept] = Field(..., description="List of concepts for this module")
    total_estimated_minutes: float = Field(..., description="Total time for all concepts")
    current_concept_id: Optional[str] = Field(None, description="Currently active concept")

class ConceptGenerationRequest(BaseModel):
    session_id: str = Field(..., description="Session identifier")
    module_id: str = Field(..., description="Module ID to generate concepts for")

class ConceptGenerationResponse(BaseModel):
    success: bool = Field(default=True)
    data: ModuleWithConcepts = Field(..., description="Module with generated concepts")
    message: str = Field(default="Concepts generated successfully")

class ConceptContentRequest(BaseModel):
    session_id: str = Field(..., description="Session identifier")
    concept_id: str = Field(..., description="Concept ID to get content for")

class ConceptContentResponse(BaseModel):
    success: bool = Field(default=True)
    data: Concept = Field(..., description="Concept with full content")
    message: str = Field(default="Concept content retrieved successfully")

class ConceptNotesRequest(BaseModel):
    session_id: str = Field(..., description="Session identifier")
    concept_id: str = Field(..., description="Concept ID to generate notes for")

class ConceptNotesResponse(BaseModel):
    success: bool = Field(default=True)
    data: Dict[str, str] = Field(..., description="Generated notes content")
    message: str = Field(default="Notes generated successfully")

class ConceptNavigationResponse(BaseModel):
    success: bool = Field(default=True)
    data: Dict[str, Any] = Field(..., description="Navigation data with concepts")
    message: str = Field(default="Navigation data retrieved successfully")
----------------------------------------
File: ./prompts.py
----------------------------------------
# ============================================================================
# File: prompts.py 
# Enhanced prompts that use rich onboarding data
# ============================================================================

COURSE_STRUCTURE_PROMPT = """
You are an expert data science educator. Create a course structure for: {topic}

Student Profile:
- Primary Goal: {goal}
- Experience Level: {level} (Detailed: {detailed_level})
- Learning Style: {style} (Detailed: {detailed_style})
- Total Time Available: {total_hours} hours ({detailed_total_time})
- Daily Commitment: {daily_minutes} minutes ({detailed_daily_time})

Technical Background Assessment:
Programming Experience: {programming_skills}
Mathematics Background: {math_background}  
Domain Knowledge: {domain_knowledge}

Based on this detailed profile:
1. Leverage their existing technical skills
2. Fill identified knowledge gaps
3. Adapt content complexity to their experience
4. Align projects with their stated goal
5. Structure modules to fit their time constraints

Create a modular course where each module is 30-60 minutes.

Return JSON:
{{
  "title": "Personalized Course Title",
  "total_modules": number,
  "student_profile_summary": "Brief summary of their background and goals",
  "learning_path_rationale": "Why this path was chosen for them",
  "modules": [
    {{
      "id": "mod_1",
      "title": "Module Title",
      "learning_objectives": ["objective1", "objective2"],
      "topics": ["topic1", "topic2"],
      "estimated_minutes": 45,
      "difficulty_level": "beginner|intermediate|advanced",
      "prerequisites_covered": ["skill1", "skill2"],
      "aligns_with_goal": "How this module helps their stated goal"
    }}
  ],
  "personalization_notes": {{
    "skipped_basics": ["concept1", "concept2"],
    "emphasis_areas": ["area1", "area2"],
    "recommended_pace": "Based on their time commitment"
  }}
}}
"""

MODULE_CONTENT_PROMPT = """
Create a {style} lesson for: {module_title}

Student Context:
- Goal: {goal}
- Experience Level: {level}
- Programming Skills: {programming_skills}
- Math Background: {math_background}
- Previous Knowledge: {domain_knowledge}

Module Details:
- Topics to cover: {topics}
- Learning objectives: {objectives}
- Target duration: {duration} minutes
- Difficulty level: {difficulty_level}

Personalization Instructions:
- Skip basics they already know: {skip_basics}
- Emphasize: {emphasis_areas}
- Connect to their goal: {goal_connection}

Format:
1. Start with personalized introduction acknowledging their background
2. Include {theory_percent}% theory and {code_percent}% hands-on code
3. Use examples relevant to their goal ({goal})
4. Add 2-3 exercises matching their programming level
5. Provide "next steps" that build toward their goal

Structure your response as:
## Personalized Introduction
[Acknowledge their background and connect to goals]

## Core Concepts  
[Theory explanation adapted to their math/programming level]

## Practical Application
[Code examples using libraries they're comfortable with]

## Hands-on Exercises
[2-3 exercises matching their skill level]

## Goal Connection
[How this module advances their stated goal]
"""

EXERCISE_GENERATOR_PROMPT = """
Create a Python coding exercise for: {topic}

Student Profile:
- Programming Level: {programming_level}
- Math Background: {math_level}
- Goal: {goal}
- Previous Domain Experience: {domain_experience}

Exercise Requirements:
- Difficulty: {difficulty}
- Focus: {focus_area}
- Time to complete: ~{estimated_minutes} minutes

Personalization:
- Use libraries they're familiar with: {familiar_libraries}
- Avoid concepts they haven't learned: {avoid_concepts}
- Connect to their goal: {goal}

Return JSON:
{{
  "title": "Exercise Title (Goal-Aligned)",
  "description": "What student needs to do (with goal context)",
  "starter_code": "def function_name():\\n    # Your code here\\n    # Hint: Use {familiar_concept} that you learned in {previous_experience}\\n    pass",
  "hints": [
    "Beginner-friendly hint based on their background",
    "Progressive hint building on their {programming_level} skills", 
    "Advanced hint connecting to their {goal}"
  ],
  "solution": "Complete solution with comments explaining concepts",
  "test_cases": [
    {{"input": "test input", "expected": "expected output"}},
    {{"input": "edge case relevant to {goal}", "expected": "expected output"}}
  ],
  "learning_notes": "What they should learn from this exercise",
  "goal_connection": "How this exercise helps achieve their {goal}"
}}
"""

COACH_HINT_PROMPT = """
Student Profile:
- Goal: {goal} 
- Experience: {experience_level}
- Programming Background: {programming_background}
- Math Background: {math_background}

Current Situation:
- Working on: {exercise_title}
- Their code: {user_code}
- Error (if any): {error}
- Attempt number: {attempt}
- Time spent: {time_spent} minutes

Coaching Instructions:
1. Reference their background knowledge positively
2. Connect hints to concepts they already understand
3. If attempt > 3, provide more specific guidance
4. Always encourage and relate back to their goal
5. Use their programming experience level to calibrate hint complexity

Provide a helpful, personalized hint that:
- Acknowledges their {experience_level} level
- Builds on their {programming_background} background  
- Connects to their goal of {goal}
- Is appropriately technical for their skill level
"""
----------------------------------------
File: ./coach_service.py
----------------------------------------
# ============================================================================
# File: coach_service.py
# Enhanced coach service with personalization
# ============================================================================

from typing import Optional, List, Dict 
from backend.services.llm_service import LLMService
from prompts import COACH_HINT_PROMPT

class CoachService:
    def __init__(self, model: str = "openai/gpt-oss-20b:free"):
        self.llm = LLMService(model=model)
        self.motivation_messages = [
            "Great progress! You're {percent}% through this module!",
            "Keep going! Just {remaining} minutes left in this session.", 
            "Nice work! You've completed {count} exercises so far.",
            "You're doing great! Remember, every expert was once a beginner.",
            "Stuck? That's normal! Try breaking down the problem into smaller steps."
        ]
    
    def set_model(self, model: str):
        """Switch models for the coach service"""
        self.llm.set_model(model)

    def get_hint(self, exercise: Dict, user_code: str, attempt: int, 
                 student_context: Dict = None, error: Optional[str] = None) -> str:
        """Generate contextual hint using student background"""
        
        # Use student context if available, otherwise use defaults
        context = student_context or {
            'goal': 'general learning',
            'experience_level': 'beginner',
            'programming_skills': ['basic'],
            'math_background': ['high-school'],
            'time_spent': 0
        }
        
        prompt = COACH_HINT_PROMPT.format(
            goal=context.get('goal', 'general learning'),
            experience_level=context.get('experience_level', 'beginner'),
            programming_background=', '.join(context.get('programming_skills', [])) or 'basic',
            math_background=', '.join(context.get('math_background', [])) or 'high school level',
            exercise_title=exercise.get('title', ''),
            user_code=user_code,
            error=error or "No error",
            attempt=attempt,
            time_spent=context.get('time_spent', 0)
        )
        
        hint = self.llm.generate(
            "You are a supportive, personalized coding tutor. Adapt your teaching style to the student's background.",
            prompt,
            temperature=0.6
        )
        return hint
    
    def answer_question(self, question: str, context: Dict, student_context: Dict = None) -> str:
        """Answer conceptual questions with personalization"""
        
        student_info = ""
        if student_context:
            student_info = f"""
            Student Background:
            - Goal: {student_context.get('goal', 'general learning')}
            - Experience: {student_context.get('experience_level', 'beginner')}
            - Programming: {', '.join(student_context.get('programming_skills', [])) or 'basic'}
            """
        
        prompt = f"""
        {student_info}
        
        Current Context: {context.get('module_title', 'Unknown')}
        Student Question: {question}
        
        Provide a clear, personalized answer that:
        1. Matches their experience level
        2. References concepts they already know
        3. Connects to their learning goal
        4. Uses appropriate technical depth
        
        Keep it under 200 words and be encouraging.
        """
        
        answer = self.llm.generate(
            "You are a knowledgeable data science tutor who personalizes explanations.",
            prompt
        )
        return answer
    
    def get_motivation(self, progress: float, time_spent: int, exercises_done: int, 
                      student_context: Dict = None) -> str:
        """Generate motivational message with personalization"""
        
        goal = student_context.get('goal', 'learning') if student_context else 'learning'
        
        if progress < 0.3:
            return f"Great start on your {goal} journey! You're {int(progress*100)}% through this module."
        elif progress < 0.7:
            return f"Halfway there! You're making excellent progress toward your {goal} goal."
        elif progress < 0.9:
            return f"Almost done! Just a little more to master this concept for your {goal}."
        else:
            return f"Fantastic! You're about to complete this module. Your {goal} skills are growing!"
    
    def check_understanding(self, module_content: str, user_responses: List[str], 
                           student_context: Dict = None) -> Dict:
        """Personalized comprehension check"""
        
        context_info = ""
        if student_context:
            context_info = f"Student goal: {student_context.get('goal', 'learning')}, Experience: {student_context.get('experience_level', 'beginner')}"
        
        prompt = f"""
        {context_info}
        Module covered: {module_content[:500]}...
        Student responses to exercises: {user_responses}
        
        Based on their background and responses, assess:
        1. Understanding level (1-5) 
        2. Areas needing reinforcement
        3. Readiness for next concepts
        4. Personalized feedback for their goal
        
        Return JSON: {{"understanding": 1-5, "weak_areas": [], "feedback": "...", "next_recommendations": []}}
        """
        
        assessment = self.llm.generate_json(
            "Assess student understanding with personalized recommendations.",
            prompt
        )
        return assessment
----------------------------------------
File: ./test_openrouter.py
----------------------------------------
import requests
import json
import os
from dotenv import load_dotenv

load_dotenv()

def test_openrouter():
    # Try to get API key from environment first, then fallback to hardcoded
    OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
    
    if not OPENROUTER_API_KEY:
        # If no environment variable, ask for input
        print("🔑 OpenRouter API Key not found in environment variables.")
        print("You can either:")
        print("1. Set environment variable: export OPENROUTER_API_KEY='your-key'")
        print("2. Enter it below (or edit the script)")
        print()
        OPENROUTER_API_KEY = input("Enter your OpenRouter API key: ").strip()
    
    if not OPENROUTER_API_KEY or OPENROUTER_API_KEY == "your-key-here":
        print("❌ No valid API key provided!")
        print("Get your key from: https://openrouter.ai/keys")
        return
    
    print(f"🔑 Using API key: {OPENROUTER_API_KEY[:10]}...{OPENROUTER_API_KEY[-4:]}")
    
    # Test with a simpler request first
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Simple test payload
    payload = {
        "model": "google/gemma-3n-e2b-it:free",
        "messages": [
            {"role": "user", "content": "Say hello"}
        ],
        "max_tokens": 50
    }
    
    print("🧪 Testing simple request first...")
    
    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        print(f"📡 Response Status: {response.status_code}")
        
        if response.status_code == 200:
            print("✅ API Key works! Testing course generation...")
            test_course_generation(OPENROUTER_API_KEY)
        elif response.status_code == 401:
            print("❌ Invalid API key!")
            print("Response:", response.json())
            print("\n🔧 Troubleshooting:")
            print("1. Make sure you copied the FULL key from https://openrouter.ai/keys")
            print("2. The key should start with 'sk-or-v1-'")
            print("3. Try creating a new key")
        elif response.status_code == 429:
            print("⚠️ Rate limited - but API key works!")
            print("Free model limits: 20 req/min, 50 req/day")
        else:
            print(f"❌ Error: {response.status_code}")
            print("Response:", response.text)
            
    except Exception as e:
        print(f"💥 Error: {e}")

def test_course_generation(api_key):
    """Test the actual course generation"""
    
    prompt = """Create a course structure for: Python for Data Science

Student Profile:
- Level: beginner
- Style Preference: practical
- Total Time: 10 hours
- Daily Time: 30 minutes per day

Create a modular course where each module is 30-60 minutes.

Return JSON with this structure:
{
  "title": "Course Title",
  "total_modules": 5,
  "modules": [
    {
      "id": "mod_1",
      "title": "Module Title", 
      "learning_objectives": ["objective1", "objective2"],
      "topics": ["topic1", "topic2"],
      "estimated_minutes": 45
    }
  ]
}"""

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "openai/gpt-oss-20b:free",
        "messages": [
            {"role": "system", "content": "You are a course designer. Return only valid JSON."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3
    }
    
    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            print("✅ Course Generation SUCCESS!")
            print("Raw response:")
            print("-" * 50)
            print(content)
            print("-" * 50)
            
            # Try to parse JSON
            try:
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0]
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0]
                
                course_data = json.loads(content.strip())
                print("🎉 JSON Parse SUCCESS!")
                print(f"📚 Title: {course_data.get('title')}")
                print(f"📦 Modules: {course_data.get('total_modules')}")
                
            except json.JSONDecodeError as e:
                print(f"⚠️ JSON parse failed: {e}")
                print("But the API call worked!")
                
        else:
            print(f"❌ Course generation failed: {response.status_code}")
            print(response.text)
            
    except Exception as e:
        print(f"💥 Course generation error: {e}")

if __name__ == "__main__":
    test_openrouter()
----------------------------------------
File: ./api/routes/concept_routes.py
----------------------------------------
# ============================================================================
# File: api/routes/concept_routes.py
# API routes for concept generation and content management
# ============================================================================

from fastapi import APIRouter, HTTPException, Depends
from typing import Dict, Any
import logging

from generators.concept_generator import ConceptGenerator
from services.learning_path_service import learning_path_service
from models.concept_models import (
    ConceptGenerationRequest, ConceptGenerationResponse,
    ConceptContentRequest, ConceptContentResponse,
    ConceptNotesRequest, ConceptNotesResponse,
    ConceptNavigationResponse
)
from domains.data_science.prompts.concept_prompts import (
    get_concept_generation_prompt,
    get_concept_content_prompt,
    get_concept_notes_prompt
)
from domains.data_science.config import DataScienceConfig

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/concepts", tags=["Concepts"])

# Dependency to get concept generator
def get_concept_generator() -> ConceptGenerator:
    return ConceptGenerator()

@router.post("/generate", response_model=ConceptGenerationResponse)
async def generate_concepts(
    request: ConceptGenerationRequest,
    concept_generator: ConceptGenerator = Depends(get_concept_generator)
):
    """
    Generate concepts for a specific module
    """
    try:
        logger.info(f"Generating concepts for module {request.module_id} in session {request.session_id}")
        
        # Get learning path and module data
        learning_path = learning_path_service.get_learning_path(request.session_id)
        if not learning_path:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        # Get module data from stored modules
        module_data = learning_path_service.get_module_data(request.session_id, request.module_id)
        if not module_data:
            raise HTTPException(status_code=404, detail="Module not found")
        
        # Check if concepts already exist
        existing_concepts = learning_path_service.get_module_concepts(request.session_id, request.module_id)
        if existing_concepts:
            logger.info(f"Concepts already exist for module {request.module_id}")
            return ConceptGenerationResponse(
                data=existing_concepts,
                message="Concepts already generated for this module"
            )
        
        # Get domain configuration
        toc = learning_path_service.get_toc(request.session_id)
        if toc.domain == "data_science":
            domain_config = DataScienceConfig.get_config()
            domain_prompt_fn = get_concept_generation_prompt
        else:
            raise HTTPException(
                status_code=400, 
                detail=f"Domain '{toc.domain}' not supported for concept generation"
            )
        
        # Generate concepts
        module_with_concepts = concept_generator.generate_concepts(
            module_data=module_data,
            user_preferences=learning_path.user_preferences or {},
            domain_prompt_fn=domain_prompt_fn,
            domain_config=domain_config
        )
        
        # Store generated concepts
        learning_path_service.store_module_concepts(request.session_id, module_with_concepts)
        
        logger.info(f"Successfully generated {len(module_with_concepts.concepts)} concepts for module {request.module_id}")
        
        return ConceptGenerationResponse(
            data=module_with_concepts,
            message=f"Generated {len(module_with_concepts.concepts)} concepts successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Concept generation failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Concept generation failed: {str(e)}")

@router.post("/content", response_model=ConceptContentResponse)
async def generate_concept_content(
    request: ConceptContentRequest,
    concept_generator: ConceptGenerator = Depends(get_concept_generator)
):
    """
    Generate detailed content for a specific concept
    """
    try:
        logger.info(f"Generating content for concept {request.concept_id}")
        
        # Get learning path and concept data
        learning_path = learning_path_service.get_learning_path(request.session_id)
        if not learning_path:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        concept_data, module_data = learning_path_service.get_concept_data(
            request.session_id, 
            request.concept_id
        )
        if not concept_data:
            raise HTTPException(status_code=404, detail="Concept not found")
        
        # Check if content already exists
        if concept_data.get('content_blocks') and len(concept_data['content_blocks']) > 0:
            logger.info(f"Content already exists for concept {request.concept_id}")
            from models.concept_models import Concept
            concept = Concept(**concept_data)
            return ConceptContentResponse(
                data=concept,
                message="Content already generated for this concept"
            )
        
        # Get domain configuration
        toc = learning_path_service.get_toc(request.session_id)
        if toc.domain == "data_science":
            domain_content_prompt_fn = get_concept_content_prompt
        else:
            raise HTTPException(
                status_code=400, 
                detail=f"Domain '{toc.domain}' not supported for content generation"
            )
        
        # Generate content
        concept = concept_generator.generate_concept_content(
            concept_data=concept_data,
            module_data=module_data,
            user_preferences=learning_path.user_preferences or {},
            domain_content_prompt_fn=domain_content_prompt_fn
        )
        
        # Store generated content
        learning_path_service.store_concept_content(request.session_id, concept)
        
        logger.info(f"Successfully generated content for concept {request.concept_id}")
        
        return ConceptContentResponse(
            data=concept,
            message="Content generated successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Content generation failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Content generation failed: {str(e)}")

@router.post("/notes", response_model=ConceptNotesResponse)
async def generate_concept_notes(
    request: ConceptNotesRequest,
    concept_generator: ConceptGenerator = Depends(get_concept_generator)
):
    """
    Generate study notes for a specific concept
    """
    try:
        logger.info(f"Generating notes for concept {request.concept_id}")
        
        # Get learning path and concept data
        learning_path = learning_path_service.get_learning_path(request.session_id)
        if not learning_path:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        concept_data, module_data = learning_path_service.get_concept_data(
            request.session_id, 
            request.concept_id
        )
        if not concept_data:
            raise HTTPException(status_code=404, detail="Concept not found")
        
        # Check if notes already exist
        if concept_data.get('notes_summary'):
            logger.info(f"Notes already exist for concept {request.concept_id}")
            return ConceptNotesResponse(
                data={"notes": concept_data['notes_summary']},
                message="Notes already generated for this concept"
            )
        
        # Get domain configuration
        toc = learning_path_service.get_toc(request.session_id)
        if toc.domain == "data_science":
            domain_notes_prompt_fn = get_concept_notes_prompt
        else:
            raise HTTPException(
                status_code=400, 
                detail=f"Domain '{toc.domain}' not supported for notes generation"
            )
        
        # Generate notes
        notes_content = concept_generator.generate_concept_notes(
            concept_data=concept_data,
            module_data=module_data,
            user_preferences=learning_path.user_preferences or {},
            domain_notes_prompt_fn=domain_notes_prompt_fn
        )
        
        # Store generated notes
        learning_path_service.store_concept_notes(request.session_id, request.concept_id, notes_content)
        
        logger.info(f"Successfully generated notes for concept {request.concept_id}")
        
        return ConceptNotesResponse(
            data={"notes": notes_content},
            message="Notes generated successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Notes generation failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Notes generation failed: {str(e)}")

@router.get("/session/{session_id}/module/{module_id}")
async def get_module_concepts(session_id: str, module_id: str):
    """
    Get all concepts for a specific module
    """
    try:
        module_concepts = learning_path_service.get_module_concepts(session_id, module_id)
        if not module_concepts:
            raise HTTPException(status_code=404, detail="Concepts not found for this module")
        
        return ConceptGenerationResponse(
            data=module_concepts,
            message="Module concepts retrieved successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving module concepts: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/session/{session_id}/concept/{concept_id}")
async def get_concept_details(session_id: str, concept_id: str):
    """
    Get detailed information about a specific concept
    """
    try:
        concept_data, module_data = learning_path_service.get_concept_data(session_id, concept_id)
        if not concept_data:
            raise HTTPException(status_code=404, detail="Concept not found")
        
        from models.concept_models import Concept
        concept = Concept(**concept_data)
        
        return ConceptContentResponse(
            data=concept,
            message="Concept details retrieved successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving concept details: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/session/{session_id}/concept/{concept_id}/progress")
async def update_concept_progress(session_id: str, concept_id: str, status: str):
    """
    Update progress status for a concept
    """
    try:
        # Validate status
        from models.concept_models import ConceptStatus
        valid_statuses = [status.value for status in ConceptStatus]
        if status not in valid_statuses:
            raise HTTPException(status_code=400, detail=f"Invalid status. Must be one of: {valid_statuses}")
        
        # Update progress
        learning_path_service.update_concept_progress(session_id, concept_id, status)
        
        return {
            "success": True,
            "message": f"Concept progress updated to {status}",
            "data": {
                "concept_id": concept_id,
                "status": status
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating concept progress: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/session/{session_id}/navigation")
async def get_concept_navigation(session_id: str):
    """
    Get complete navigation data including concepts
    """
    try:
        navigation_data = learning_path_service.get_learning_path_with_concepts(session_id)
        if not navigation_data:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        return ConceptNavigationResponse(
            data=navigation_data,
            message="Concept navigation data retrieved successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving concept navigation: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
----------------------------------------
File: ./api/routes/module_routes.py
----------------------------------------
# ============================================================================
# File: api/routes/module_routes.py
# API routes for module generation and management
# ============================================================================

from fastapi import APIRouter, HTTPException, Depends
from typing import Dict, Any
import logging

from generators.module_generator import ModuleGenerator
from services.learning_path_service import learning_path_service
from models.module_models import ModuleGenerationRequest, ModuleGenerationResponse
from domains.data_science.prompts.module_prompts import get_module_prompt
from domains.data_science.config import DataScienceConfig

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/modules", tags=["Modules"])

# Dependency to get module generator
def get_module_generator() -> ModuleGenerator:
    return ModuleGenerator()

@router.post("/generate", response_model=ModuleGenerationResponse)
async def generate_modules(
    request: ModuleGenerationRequest,
    module_generator: ModuleGenerator = Depends(get_module_generator)
):
    """
    Generate modules for a specific topic
    """
    try:
        logger.info(f"Generating modules for topic {request.topic_id} in session {request.session_id}")
        
        # Get learning path and TOC data
        learning_path = learning_path_service.get_learning_path(request.session_id)
        if not learning_path:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        toc = learning_path_service.get_toc(request.session_id)
        if not toc:
            raise HTTPException(status_code=404, detail="TOC not found")
        
        # Validate topic ID is in learning path
        if request.topic_id not in learning_path.selected_topics:
            raise HTTPException(status_code=400, detail="Topic not in learning path")
        
        # Find topic data in TOC
        topic_data = None
        for topic in toc.topics:
            if topic.id == request.topic_id:
                topic_data = topic.dict()
                break
        
        if not topic_data:
            raise HTTPException(status_code=404, detail="Topic not found in TOC")
        
        # Check if modules already exist
        existing_modules = learning_path_service.get_topic_modules(request.session_id, request.topic_id)
        if existing_modules:
            logger.info(f"Modules already exist for topic {request.topic_id}")
            return ModuleGenerationResponse(
                data=existing_modules,
                message="Modules already generated for this topic"
            )
        
        # Get domain configuration
        if toc.domain == "data_science":
            domain_config = DataScienceConfig.get_config()
            domain_prompt_fn = get_module_prompt
        else:
            raise HTTPException(
                status_code=400, 
                detail=f"Domain '{toc.domain}' not supported for module generation"
            )
        
        # Generate modules
        topic_with_modules = module_generator.generate_modules(
            topic_data=topic_data,
            user_preferences=learning_path.user_preferences or {},
            domain_prompt_fn=domain_prompt_fn,
            domain_config=domain_config
        )
        
        # Store generated modules
        learning_path_service.store_topic_modules(request.session_id, topic_with_modules)
        
        logger.info(f"Successfully generated {len(topic_with_modules.modules)} modules for topic {request.topic_id}")
        
        return ModuleGenerationResponse(
            data=topic_with_modules,
            message=f"Generated {len(topic_with_modules.modules)} modules successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Module generation failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Module generation failed: {str(e)}")

@router.get("/session/{session_id}/topic/{topic_id}")
async def get_topic_modules(session_id: str, topic_id: str):
    """
    Get modules for a specific topic
    """
    try:
        topic_modules = learning_path_service.get_topic_modules(session_id, topic_id)
        if not topic_modules:
            raise HTTPException(status_code=404, detail="Modules not found for this topic")
        
        return ModuleGenerationResponse(
            data=topic_modules,
            message="Modules retrieved successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving modules: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/session/{session_id}")
async def get_all_session_modules(session_id: str):
    """
    Get all generated modules for a session
    """
    try:
        all_modules = learning_path_service.get_all_session_modules(session_id)
        
        return {
            "success": True,
            "data": {
                "session_id": session_id,
                "topics": all_modules,
                "total_topics_with_modules": len(all_modules)
            },
            "message": f"Retrieved modules for {len(all_modules)} topics"
        }
        
    except Exception as e:
        logger.error(f"Error retrieving session modules: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/session/{session_id}/select")
async def update_current_selection(session_id: str, topic_id: str, module_id: str = None):
    """
    Update the current topic and module selection
    """
    try:
        # Validate session exists
        learning_path = learning_path_service.get_learning_path(session_id)
        if not learning_path:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        # Validate topic is in learning path
        if topic_id not in learning_path.selected_topics:
            raise HTTPException(status_code=400, detail="Topic not in learning path")
        
        # If module_id provided, validate it exists
        if module_id:
            topic_modules = learning_path_service.get_topic_modules(session_id, topic_id)
            if not topic_modules:
                raise HTTPException(status_code=404, detail="No modules found for this topic")
            
            module_exists = any(module.id == module_id for module in topic_modules.modules)
            if not module_exists:
                raise HTTPException(status_code=400, detail="Module not found in topic")
        
        # Update selection
        learning_path_service.set_current_selection(session_id, topic_id, module_id)
        
        return {
            "success": True,
            "data": {
                "session_id": session_id,
                "current_topic_id": topic_id,
                "current_module_id": module_id
            },
            "message": "Selection updated successfully"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating selection: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/session/{session_id}/current")
async def get_current_selection(session_id: str):
    """
    Get current topic and module selection
    """
    try:
        current_selection = learning_path_service.get_current_selection(session_id)
        
        return {
            "success": True,
            "data": current_selection,
            "message": "Current selection retrieved successfully"
        }
        
    except Exception as e:
        logger.error(f"Error retrieving current selection: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/session/{session_id}/navigation")
async def get_navigation_data(session_id: str):
    """
    Get complete navigation data for the learning path
    """
    try:
        navigation_data = learning_path_service.get_learning_path_with_modules(session_id)
        if not navigation_data:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        return {
            "success": True,
            "data": navigation_data,
            "message": "Navigation data retrieved successfully"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving navigation data: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
----------------------------------------
File: ./api/routes/toc_routes.py
----------------------------------------
# ============================================================================
# File: api/routes/toc_routes.py
# API routes for TOC generation and learning path creation
# ============================================================================

from fastapi import APIRouter, HTTPException, Depends
from typing import Dict, Any, List
from pydantic import BaseModel, Field
import uuid
import logging

from generators.toc_generator import TOCGenerator
from services.learning_path_service import learning_path_service
from models.toc_models import TOCResponse, LearningPathResponse
from domains.data_science.prompts.toc_prompts import get_toc_prompt

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/toc", tags=["Table of Contents"])

# Request models
class TOCRequest(BaseModel):
    domain: str = Field(..., description="Domain for curriculum (e.g., 'data_science')")
    user_preferences: Dict[str, Any] = Field(..., description="User preferences from onboarding")

class LearningPathRequest(BaseModel):
    session_id: str = Field(..., description="Session ID from TOC generation")
    user_id: str = Field(..., description="User identifier")
    selected_topic_ids: List[str] = Field(..., description="List of selected topic IDs")

class LearningPathUpdateRequest(BaseModel):
    session_id: str = Field(..., description="Session ID")
    selected_topic_ids: List[str] = Field(..., description="Updated list of selected topic IDs")

# Dependency to get TOC generator
def get_toc_generator() -> TOCGenerator:
    return TOCGenerator()

@router.post("/generate", response_model=TOCResponse)
async def generate_toc(
    request: TOCRequest,
    toc_generator: TOCGenerator = Depends(get_toc_generator)
):
    """
    Generate Table of Contents based on domain and user preferences
    """
    try:
        session_id = str(uuid.uuid4())
        
        logger.info(f"Generating TOC for domain: {request.domain}")
        logger.info(f"Session ID: {session_id}")
        
        # Get domain-specific prompt
        if request.domain == "data_science":
            domain_prompt = get_toc_prompt(request.user_preferences)
        else:
            raise HTTPException(
                status_code=400, 
                detail=f"Domain '{request.domain}' not supported yet"
            )
        
        # Generate TOC
        toc = toc_generator.generate_toc(
            domain=request.domain,
            user_preferences=request.user_preferences,
            domain_prompt=domain_prompt
        )
        
        # Store TOC in learning path service
        learning_path_service.store_toc(session_id, toc)
        
        logger.info(f"Successfully generated TOC with {len(toc.topics)} topics")
        
        return TOCResponse(
            data=toc,
            message=f"TOC generated successfully for {request.domain}"
        )
        
    except Exception as e:
        logger.error(f"TOC generation failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"TOC generation failed: {str(e)}")

@router.get("/session/{session_id}")
async def get_toc_by_session(session_id: str):
    """
    Retrieve TOC by session ID
    """
    try:
        toc = learning_path_service.get_toc(session_id)
        if not toc:
            raise HTTPException(status_code=404, detail="TOC not found")
        
        return TOCResponse(
            data=toc,
            message="TOC retrieved successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving TOC: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/learning-path", response_model=LearningPathResponse)
async def create_learning_path(request: LearningPathRequest):
    """
    Create learning path from selected topics
    """
    try:
        logger.info(f"Creating learning path for user {request.user_id}")
        logger.info(f"Selected topics: {request.selected_topic_ids}")
        
        learning_path = learning_path_service.create_learning_path(
            user_id=request.user_id,
            session_id=request.session_id,
            selected_topic_ids=request.selected_topic_ids
        )
        
        return LearningPathResponse(
            data=learning_path,
            message=f"Learning path created with {len(request.selected_topic_ids)} topics"
        )
        
    except ValueError as e:
        logger.error(f"Invalid learning path request: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Learning path creation failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.put("/learning-path", response_model=LearningPathResponse)
async def update_learning_path(request: LearningPathUpdateRequest):
    """
    Update existing learning path with new topic selection
    """
    try:
        logger.info(f"Updating learning path for session {request.session_id}")
        
        learning_path = learning_path_service.update_learning_path(
            session_id=request.session_id,
            selected_topic_ids=request.selected_topic_ids
        )
        
        return LearningPathResponse(
            data=learning_path,
            message=f"Learning path updated with {len(request.selected_topic_ids)} topics"
        )
        
    except ValueError as e:
        logger.error(f"Invalid learning path update: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Learning path update failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/learning-path/{session_id}")
async def get_learning_path(session_id: str):
    """
    Get learning path by session ID
    """
    try:
        learning_path = learning_path_service.get_learning_path(session_id)
        if not learning_path:
            raise HTTPException(status_code=404, detail="Learning path not found")
        
        return LearningPathResponse(
            data=learning_path,
            message="Learning path retrieved successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving learning path: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/user/{user_id}/learning-paths")
async def get_user_learning_paths(user_id: str):
    """
    Get all learning paths for a user
    """
    try:
        learning_paths = learning_path_service.get_user_learning_paths(user_id)
        
        return {
            "success": True,
            "data": learning_paths,
            "count": len(learning_paths),
            "message": f"Retrieved {len(learning_paths)} learning paths"
        }
        
    except Exception as e:
        logger.error(f"Error retrieving user learning paths: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/topic/{session_id}/{topic_id}")
async def get_topic_details(session_id: str, topic_id: str):
    """
    Get detailed information about a specific topic
    """
    try:
        topic_details = learning_path_service.get_topic_details(session_id, topic_id)
        if not topic_details:
            raise HTTPException(status_code=404, detail="Topic not found")
        
        return {
            "success": True,
            "data": topic_details,
            "message": "Topic details retrieved successfully"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving topic details: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/statistics")
async def get_toc_statistics():
    """
    Get TOC service statistics
    """
    try:
        stats = learning_path_service.get_statistics()
        return {
            "success": True,
            "data": stats,
            "message": "Statistics retrieved successfully"
        }
        
    except Exception as e:
        logger.error(f"Error retrieving statistics: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
----------------------------------------
File: ./api/routes/onboarding_routes.py
----------------------------------------
# ============================================================================
# File: api/routes/onboarding_routes.py
# API routes for generic onboarding question generation
# ============================================================================

from fastapi import APIRouter, HTTPException
from typing import Dict, Any, List
from pydantic import BaseModel, Field
import logging
import json

from services.llm_service import LLMService

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/onboarding", tags=["Onboarding"])

class QuestionGenerationRequest(BaseModel):
    learning_topic: str = Field(..., description="What the user wants to learn")
    daily_time: str = Field(..., description="Daily time commitment (e.g., '30min')")
    total_duration: str = Field(..., description="Total duration (e.g., '2weeks')")

class QuestionOption(BaseModel):
    value: str = Field(..., description="Option value")
    label: str = Field(..., description="Option display text")

class Question(BaseModel):
    id: str = Field(..., description="Unique question identifier")
    question: str = Field(..., description="Question text")
    type: str = Field(..., description="Question type: 'single_choice' or 'multiple_choice'")
    options: List[QuestionOption] = Field(..., description="Available answer options")

class QuestionGenerationResponse(BaseModel):
    success: bool = Field(default=True)
    questions: List[Question] = Field(..., description="Generated personalization questions")
    message: str = Field(default="Questions generated successfully")

def get_question_generation_prompt(learning_topic: str, daily_time: str, total_duration: str) -> str:
    """Generate prompt for LLM to create personalized questions"""
    
    return f"""
You are an expert curriculum designer. Generate exactly 4 personalized questions to help create the best learning experience for someone who wants to learn: "{learning_topic}"

Time commitment: {daily_time} daily for {total_duration}

Create questions that help determine:
1. Their current experience level with this topic
2. Their preferred learning style (hands-on vs theory)
3. Their specific goals or applications they're interested in
4. Their technical background relevant to this topic

IMPORTANT REQUIREMENTS:
- Generate exactly 4 questions (no more, no less)
- Each question must have 3-4 answer options
- Use only these question types: "single_choice" or "multiple_choice"
- Questions should be specific to "{learning_topic}" - not generic
- Include a mix of experience, learning style, and goal-oriented questions
- Make options realistic and cover the full spectrum (beginner to advanced)

Return ONLY valid JSON in this exact format:
{{
  "questions": [
    {{
      "id": "experience_level",
      "question": "What's your current experience with {learning_topic}?",
      "type": "single_choice",
      "options": [
        {{"value": "complete_beginner", "label": "Complete beginner - never worked with this before"}},
        {{"value": "some_exposure", "label": "Some exposure through courses or tutorials"}},
        {{"value": "practical_experience", "label": "Some practical experience in projects"}},
        {{"value": "advanced", "label": "Advanced - looking to deepen specific areas"}}
      ]
    }},
    {{
      "id": "learning_goals",
      "question": "What's your primary goal for learning {learning_topic}?",
      "type": "single_choice",
      "options": [
        {{"value": "career_change", "label": "Career change or new job opportunities"}},
        {{"value": "skill_enhancement", "label": "Enhance skills for current role"}},
        {{"value": "personal_projects", "label": "Work on personal projects and interests"}},
        {{"value": "academic", "label": "Academic or research purposes"}}
      ]
    }},
    {{
      "id": "learning_style",
      "question": "How do you learn best?",
      "type": "single_choice",
      "options": [
        {{"value": "hands_on", "label": "Hands-on practice - learn by doing (80% practice, 20% theory)"}},
        {{"value": "balanced", "label": "Balanced approach - mix of theory and practice (60% practice, 40% theory)"}},
        {{"value": "theory_first", "label": "Theory first - understand concepts deeply before applying (40% practice, 60% theory)"}}
      ]
    }},
    {{
      "id": "background_knowledge",
      "question": "What relevant background do you have for {learning_topic}?",
      "type": "multiple_choice",
      "options": [
        {{"value": "programming", "label": "Programming/coding experience"}},
        {{"value": "math_stats", "label": "Mathematics or statistics background"}},
        {{"value": "domain_experience", "label": "Experience in related field"}},
        {{"value": "none", "label": "No relevant background"}}
      ]
    }}
  ]
}}

Examples for different topics:

For "Machine Learning":
- Ask about programming experience (Python, R, etc.)
- Ask about math background (statistics, linear algebra)
- Ask about specific ML applications they're interested in
- Ask about their experience with data

For "Digital Marketing":
- Ask about current marketing experience
- Ask about specific channels they want to focus on
- Ask about business context (startup, enterprise, agency)
- Ask about technical comfort level

For "Project Management":
- Ask about current role and team size
- Ask about methodology preferences (Agile, Waterfall, etc.)
- Ask about industry context
- Ask about certification goals

Make the questions specific and relevant to "{learning_topic}".
"""

@router.post("/generate-questions", response_model=QuestionGenerationResponse)
async def generate_personalization_questions(request: QuestionGenerationRequest):
    """
    Generate personalized questions for onboarding based on learning topic
    """
    try:
        logger.info(f"Generating questions for topic: {request.learning_topic}")
        
        # Validate learning topic (basic guardrails)
        topic_lower = request.learning_topic.lower().strip()
        
        # Basic content filtering
        invalid_patterns = ['cook', 'recipe', 'food', 'game', 'entertainment']
        if any(pattern in topic_lower for pattern in invalid_patterns):
            raise HTTPException(
                status_code=400, 
                detail="Please enter a professional skill or educational topic"
            )
        
        if len(request.learning_topic.strip()) < 3:
            raise HTTPException(
                status_code=400,
                detail="Learning topic must be at least 3 characters long"
            )
        
        # Generate prompt
        prompt = get_question_generation_prompt(
            request.learning_topic,
            request.daily_time,
            request.total_duration
        )
        
        # Call LLM service
        llm_service = LLMService()
        
        system_prompt = """You are an expert curriculum designer who creates personalized learning experiences. 
        
        Generate exactly 4 questions that will help personalize a learning curriculum for the given topic.
        
        Return ONLY valid JSON in the specified format. Do not include any explanation or additional text."""
        
        response = llm_service.generate(
            system_prompt=system_prompt,
            user_prompt=prompt,
            temperature=0.7
        )
        
        logger.info(f"LLM Raw response: {response}")
        
        # Parse the JSON response
        try:
            # Clean the response to extract JSON
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0]
            elif "```" in json_str:
                json_str = json_str.split("```")[1].split("```")[0]
            
            json_str = json_str.strip()
            logger.info(f"Cleaned JSON string: {json_str}")
            
            questions_data = json.loads(json_str)
            
            # Validate the structure
            if "questions" not in questions_data:
                raise ValueError("Response missing 'questions' field")
            
            questions = []
            for i, q in enumerate(questions_data["questions"]):
                # Ensure required fields
                question = Question(
                    id=q.get("id", f"question_{i+1}"),
                    question=q["question"],
                    type=q["type"],
                    options=[
                        QuestionOption(value=opt["value"], label=opt["label"]) 
                        for opt in q["options"]
                    ]
                )
                questions.append(question)
            
            # Validate question count
            if len(questions) != 4:
                logger.warning(f"Generated {len(questions)} questions, expected exactly 4")
                # If we don't have exactly 4, fall back
                if len(questions) < 3:
                    return generate_fallback_questions(request.learning_topic)
            
            logger.info(f"Successfully generated {len(questions)} questions for {request.learning_topic}")
            
            return QuestionGenerationResponse(
                questions=questions,
                message=f"Generated {len(questions)} personalization questions"
            )
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM JSON response: {e}")
            logger.error(f"Raw response: {response}")
            
            # Fallback to generic questions
            return generate_fallback_questions(request.learning_topic)
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Question generation failed: {str(e)}")
        
        # Fallback to generic questions
        return generate_fallback_questions(request.learning_topic)

def generate_fallback_questions(learning_topic: str) -> QuestionGenerationResponse:
    """Generate fallback questions when LLM fails"""
    
    questions = [
        Question(
            id="experience_level",
            question=f"What's your current experience level with {learning_topic}?",
            type="single_choice",
            options=[
                QuestionOption(value="beginner", label="Complete beginner"),
                QuestionOption(value="some_experience", label="Some experience"),
                QuestionOption(value="intermediate", label="Intermediate level"),
                QuestionOption(value="advanced", label="Advanced practitioner")
            ]
        ),
        Question(
            id="learning_style",
            question="How do you prefer to learn?",
            type="single_choice",
            options=[
                QuestionOption(value="hands_on", label="Hands-on practice (80% doing, 20% theory)"),
                QuestionOption(value="balanced", label="Balanced approach (60% doing, 40% theory)"),
                QuestionOption(value="theory_first", label="Theory first (40% doing, 60% theory)")
            ]
        ),
        Question(
            id="learning_goals",
            question=f"What's your primary goal for learning {learning_topic}?",
            type="single_choice",
            options=[
                QuestionOption(value="career", label="Career advancement or job opportunities"),
                QuestionOption(value="skills", label="Enhance skills for current role"),
                QuestionOption(value="personal", label="Personal projects and interests"),
                QuestionOption(value="academic", label="Academic or research purposes")
            ]
        ),
        Question(
            id="technical_background",
            question="What technical skills do you already have?",
            type="multiple_choice",
            options=[
                QuestionOption(value="programming", label="Programming experience"),
                QuestionOption(value="databases", label="Database knowledge"),
                QuestionOption(value="statistics", label="Statistics/Math background"),
                QuestionOption(value="none", label="No technical background")
            ]
        )
    ]
    
    return QuestionGenerationResponse(
        questions=questions,
        message=f"Generated fallback questions for {learning_topic}"
    )
----------------------------------------
File: ./generators/toc_generator.py
----------------------------------------
# ============================================================================
# File: generators/toc_generator.py
# Completely generic TOC generator - no opinions, just passes data to LLM
# ============================================================================

from typing import Dict, Any
from services.llm_service import LLMService
from models.toc_models import TableOfContents
import logging

logger = logging.getLogger(__name__)

class TOCGenerator:
    def __init__(self, model: str = "openai/gpt-oss-20b:free"):
        self.llm = LLMService(model=model)
    
    def generate_toc(self, 
                     domain: str, 
                     user_preferences: Dict[str, Any], 
                     domain_prompt: str) -> TableOfContents:
        """
        Generate Table of Contents using domain-specific prompt
        
        This is a completely generic wrapper - it doesn't make any decisions
        about the curriculum. All logic is delegated to the LLM via the domain prompt.
        
        Args:
            domain: Domain identifier (e.g., 'data_science', 'cat_exam')
            user_preferences: Complete user preferences from onboarding
            domain_prompt: Domain-specific prompt template
            
        Returns:
            TableOfContents: Structured TOC generated by LLM
        """
        
        # Simple system prompt that doesn't bias the LLM
        system_prompt = f"""You are an expert curriculum designer for {domain}. 
        
        Your job is to create a personalized Table of Contents that perfectly matches 
        the user's stated preferences and goals. 
        
        Be completely responsive to their:
        - Learning goals and objectives
        - Experience level and background
        - Time constraints and availability  
        - Learning style preferences
        - Technical background
        
        Do not impose any predetermined structure or bias. Let their preferences 
        guide every decision about topics, depth, difficulty, and focus areas.
        
        Generate a comprehensive yet personalized curriculum that they will actually 
        want to follow and complete.
        
        Return valid JSON that matches the required schema exactly."""
        
        logger.info(f"Generating TOC for domain: {domain}")
        logger.debug(f"User preferences keys: {list(user_preferences.keys())}")
        
        try:
            toc = self.llm.generate_structured(
                system_prompt=system_prompt,
                user_prompt=domain_prompt,
                response_model=TableOfContents,
                temperature=0.7  # Allow creativity while staying structured
            )
            
            logger.info(f"Successfully generated TOC with {len(toc.topics)} topics")
            logger.info(f"Total estimated hours: {toc.total_estimated_hours}")
            
            return toc
            
        except Exception as e:
            logger.error(f"Failed to generate TOC: {str(e)}")
            raise Exception(f"TOC generation failed: {str(e)}")
    
    def set_model(self, model: str):
        """Switch LLM model"""
        self.llm.set_model(model)
        logger.info(f"TOC Generator switched to model: {model}")
----------------------------------------
File: ./generators/module_generator.py
----------------------------------------
# ============================================================================
# File: generators/module_generator.py
# Generic module generator that works across domains
# ============================================================================

from typing import Dict, Any, List
from services.llm_service import LLMService
from models.module_models import TopicWithModules, Module
import logging
import uuid

logger = logging.getLogger(__name__)

class ModuleGenerator:
    def __init__(self, model: str = "openai/gpt-oss-20b:free"):
        self.llm = LLMService(model=model)
    
    def generate_modules(self, 
                        topic_data: Dict[str, Any],
                        user_preferences: Dict[str, Any],
                        domain_prompt_fn,
                        domain_config: Dict[str, Any]) -> TopicWithModules:
        """
        Generate modules for a topic using domain-specific prompts
        
        Args:
            topic_data: Topic information from TOC
            user_preferences: User preferences from onboarding
            domain_prompt_fn: Function to generate domain-specific prompt
            domain_config: Domain configuration
            
        Returns:
            TopicWithModules: Topic with generated modules
        """
        
        # Get domain-specific prompt
        domain_prompt = domain_prompt_fn(topic_data, user_preferences)
        
        # System prompt for module generation
        system_prompt = f"""You are an expert curriculum designer. 
        
        Break down the given topic into learning modules that create a coherent, 
        progressive learning experience.
        
        Follow the domain-specific guidelines and user preferences precisely.
        
        Return valid JSON that matches the required schema exactly."""
        
        logger.info(f"Generating modules for topic: {topic_data.get('name', 'Unknown')}")
        logger.debug(f"Topic difficulty: {topic_data.get('difficulty', 'Unknown')}")
        logger.debug(f"Topic hours: {topic_data.get('estimated_hours', 'Unknown')}")
        
        try:
            # Generate modules using structured output
            topic_with_modules = self.llm.generate_structured(
                system_prompt=system_prompt,
                user_prompt=domain_prompt,
                response_model=TopicWithModules,
                temperature=0.7
            )
            
            # Post-process: Add unique IDs and ensure proper ordering
            topic_with_modules = self._post_process_modules(
                topic_with_modules, 
                topic_data,
                domain_config
            )
            
            logger.info(f"Successfully generated {len(topic_with_modules.modules)} modules")
            logger.info(f"Total estimated hours: {topic_with_modules.total_estimated_hours}")
            
            return topic_with_modules
            
        except Exception as e:
            logger.error(f"Failed to generate modules: {str(e)}")
            raise Exception(f"Module generation failed: {str(e)}")
    
    def _post_process_modules(self, 
                            topic_with_modules: TopicWithModules,
                            original_topic_data: Dict[str, Any],
                            domain_config: Dict[str, Any]) -> TopicWithModules:
        """
        Post-process generated modules to ensure consistency and add missing data
        """
        
        # Ensure topic data is consistent
        topic_with_modules.topic_id = original_topic_data.get('id', str(uuid.uuid4()))
        
        # Process each module
        for i, module in enumerate(topic_with_modules.modules):
            # Ensure unique IDs
            if not module.id or module.id == "":
                module.id = f"mod_{topic_with_modules.topic_id}_{i+1}"
            
            # Ensure topic_id is set
            module.topic_id = topic_with_modules.topic_id
            
            # Ensure proper ordering
            module.order = i + 1
            
            # Validate estimated hours (set default if missing or unrealistic)
            if module.estimated_hours <= 0 or module.estimated_hours > 10:
                default_hours = domain_config.get('module_generation', {}).get('default_module_hours', 2.0)
                logger.warning(f"Adjusting unrealistic hours for module {module.name}: {module.estimated_hours} -> {default_hours}")
                module.estimated_hours = default_hours
        
        # Recalculate total estimated hours
        topic_with_modules.total_estimated_hours = sum(
            module.estimated_hours for module in topic_with_modules.modules
        )
        
        # Validate module count
        min_modules = domain_config.get('module_generation', {}).get('min_modules_per_topic', 2)
        max_modules = domain_config.get('module_generation', {}).get('max_modules_per_topic', 8)
        
        module_count = len(topic_with_modules.modules)
        if module_count < min_modules:
            logger.warning(f"Generated only {module_count} modules, minimum is {min_modules}")
        elif module_count > max_modules:
            logger.warning(f"Generated {module_count} modules, maximum is {max_modules}")
        
        return topic_with_modules
    
    def set_model(self, model: str):
        """Switch LLM model"""
        self.llm.set_model(model)
        logger.info(f"Module Generator switched to model: {model}")
----------------------------------------
File: ./generators/concept_generator.py
----------------------------------------
# ============================================================================
# File: generators/concept_generator.py
# Generic concept generator that works across domains
# ============================================================================

from typing import Dict, Any, List
from services.llm_service import LLMService
from models.concept_models import ModuleWithConcepts, Concept, ContentBlock
import logging
import uuid
import re

logger = logging.getLogger(__name__)

class ConceptGenerator:
    def __init__(self, model: str = "openai/gpt-oss-20b:free"):
        self.llm = LLMService(model=model)
    
    def generate_concepts(self, 
                         module_data: Dict[str, Any],
                         user_preferences: Dict[str, Any],
                         domain_prompt_fn,
                         domain_config: Dict[str, Any]) -> ModuleWithConcepts:
        """
        Generate concepts for a module using domain-specific prompts
        
        Args:
            module_data: Module information
            user_preferences: User preferences from onboarding
            domain_prompt_fn: Function to generate domain-specific prompt
            domain_config: Domain configuration
            
        Returns:
            ModuleWithConcepts: Module with generated concepts
        """
        
        # Get domain-specific prompt for concept generation
        domain_prompt = domain_prompt_fn(module_data, user_preferences)
        
        # System prompt for concept generation
        system_prompt = f"""You are an expert curriculum designer. 
        
        Break down the given module into learning concepts that create a coherent, 
        progressive learning experience.
        
        Each concept should be focused and digestible (10-20 minutes).
        
        Follow the domain-specific guidelines and user preferences precisely.
        
        Return valid JSON that matches the required schema exactly."""
        
        logger.info(f"Generating concepts for module: {module_data.get('name', 'Unknown')}")
        logger.debug(f"Module estimated time: {module_data.get('estimated_hours', 'Unknown')} hours")
        
        try:
            # Generate concepts using structured output
            module_with_concepts = self.llm.generate_structured(
                system_prompt=system_prompt,
                user_prompt=domain_prompt,
                response_model=ModuleWithConcepts,
                temperature=0.7
            )
            
            # Post-process: Add unique IDs and ensure proper ordering
            module_with_concepts = self._post_process_concepts(
                module_with_concepts, 
                module_data,
                domain_config
            )
            
            logger.info(f"Successfully generated {len(module_with_concepts.concepts)} concepts")
            logger.info(f"Total estimated time: {module_with_concepts.total_estimated_minutes} minutes")
            
            return module_with_concepts
            
        except Exception as e:
            logger.error(f"Failed to generate concepts: {str(e)}")
            raise Exception(f"Concept generation failed: {str(e)}")
    
    def generate_concept_content(self,
                               concept_data: Dict[str, Any],
                               module_data: Dict[str, Any],
                               user_preferences: Dict[str, Any],
                               domain_content_prompt_fn) -> Concept:
        """
        Generate detailed content for a specific concept
        """
        
        # Get domain-specific content prompt
        domain_prompt = domain_content_prompt_fn(concept_data, module_data, user_preferences)
        
        system_prompt = """You are an expert instructor. Generate detailed learning content for the given concept.
        
        Create engaging, practical content that matches the user's learning style and goals.
        
        Return markdown content structured in logical blocks for easy consumption.
        
        Focus on practical application and real-world relevance."""
        
        logger.info(f"Generating content for concept: {concept_data.get('name', 'Unknown')}")
        
        try:
            # Generate content as text (markdown)
            content_text = self.llm.generate(
                system_prompt=system_prompt,
                user_prompt=domain_prompt,
                temperature=0.7
            )
            
            # Parse content into blocks
            content_blocks = self._parse_content_into_blocks(content_text)
            
            # Update concept with content
            concept = Concept(**concept_data)
            concept.content_blocks = content_blocks
            
            logger.info(f"Generated content with {len(content_blocks)} blocks")
            
            return concept
            
        except Exception as e:
            logger.error(f"Failed to generate concept content: {str(e)}")
            raise Exception(f"Concept content generation failed: {str(e)}")
    
    def generate_concept_notes(self,
                             concept_data: Dict[str, Any],
                             module_data: Dict[str, Any],
                             user_preferences: Dict[str, Any],
                             domain_notes_prompt_fn) -> str:
        """
        Generate concise study notes for a concept
        """
        
        # Get domain-specific notes prompt
        domain_prompt = domain_notes_prompt_fn(concept_data, module_data, user_preferences)
        
        system_prompt = """You are an expert instructor. Generate concise, comprehensive study notes.
        
        Create notes that serve as a quick reference and study aid.
        
        Include key concepts, formulas, examples, and memory aids.
        
        Format as clean markdown for easy reading and reference."""
        
        logger.info(f"Generating notes for concept: {concept_data.get('name', 'Unknown')}")
        
        try:
            notes_content = self.llm.generate(
                system_prompt=system_prompt,
                user_prompt=domain_prompt,
                temperature=0.6
            )
            
            logger.info(f"Generated notes for concept")
            
            return notes_content
            
        except Exception as e:
            logger.error(f"Failed to generate concept notes: {str(e)}")
            raise Exception(f"Concept notes generation failed: {str(e)}")
    
    def _post_process_concepts(self, 
                             module_with_concepts: ModuleWithConcepts,
                             original_module_data: Dict[str, Any],
                             domain_config: Dict[str, Any]) -> ModuleWithConcepts:
        """
        Post-process generated concepts to ensure consistency and add missing data
        """
        
        # Ensure module data is consistent
        module_with_concepts.module_id = original_module_data.get('id', str(uuid.uuid4()))
        module_with_concepts.topic_id = original_module_data.get('topic_id', '')
        
        # Process each concept
        for i, concept in enumerate(module_with_concepts.concepts):
            # Ensure unique IDs
            if not concept.id or concept.id == "":
                concept.id = f"concept_{module_with_concepts.module_id}_{i+1}"
            
            # Ensure module_id is set
            concept.module_id = module_with_concepts.module_id
            
            # Ensure proper ordering
            concept.order = i + 1
            
            # Validate estimated time (should be 10-20 minutes per concept)
            if concept.estimated_minutes <= 5 or concept.estimated_minutes > 30:
                default_minutes = 15  # Default 15 minutes per concept
                logger.warning(f"Adjusting unrealistic time for concept {concept.name}: {concept.estimated_minutes} -> {default_minutes}")
                concept.estimated_minutes = default_minutes
        
        # Recalculate total estimated time
        module_with_concepts.total_estimated_minutes = sum(
            concept.estimated_minutes for concept in module_with_concepts.concepts
        )
        
        # Set first concept as current
        if module_with_concepts.concepts:
            module_with_concepts.current_concept_id = module_with_concepts.concepts[0].id
        
        # Validate concept count
        concept_count = len(module_with_concepts.concepts)
        if concept_count < 2:
            logger.warning(f"Generated only {concept_count} concepts, recommend 3-6")
        elif concept_count > 8:
            logger.warning(f"Generated {concept_count} concepts, may be too many")
        
        return module_with_concepts
    
    def _parse_content_into_blocks(self, content_text: str) -> List[ContentBlock]:
        """
        Parse markdown content into logical blocks for progressive display
        """
        
        # Split content by main headings (##)
        blocks = []
        current_block = ""
        block_counter = 1
        
        lines = content_text.split('\n')
        
        for line in lines:
            if line.strip().startswith('## ') and current_block:
                # Save previous block
                if current_block.strip():
                    blocks.append(ContentBlock(
                        id=f"block_{block_counter}",
                        type="content",
                        content=current_block.strip(),
                        order=block_counter,
                        estimated_minutes=2.0
                    ))
                    block_counter += 1
                
                # Start new block
                current_block = line + '\n'
            else:
                current_block += line + '\n'
        
        # Add final block
        if current_block.strip():
            blocks.append(ContentBlock(
                id=f"block_{block_counter}",
                type="content", 
                content=current_block.strip(),
                order=block_counter,
                estimated_minutes=2.0
            ))
        
        # If no main headings found, create single block
        if not blocks:
            blocks.append(ContentBlock(
                id="block_1",
                type="content",
                content=content_text.strip(),
                order=1,
                estimated_minutes=5.0
            ))
        
        return blocks
    
    def set_model(self, model: str):
        """Switch LLM model"""
        self.llm.set_model(model)
        logger.info(f"Concept Generator switched to model: {model}")
----------------------------------------
File: ./main.py
----------------------------------------
# ============================================================================
# File: main.py (UPDATED)
# Updated FastAPI app with onboarding question generation routes
# ============================================================================

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import logging
import os
from dotenv import load_dotenv

# Import route modules
from api.routes.toc_routes import router as toc_router
from api.routes.module_routes import router as module_router
from api.routes.concept_routes import router as concept_router
from api.routes.onboarding_routes import router as onboarding_router  # NEW: Added onboarding routes

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create FastAPI app
app = FastAPI(
    title="Learning Platform API",
    description="Modular learning platform with domain-specific curriculum generation",
    version="4.1.0"  # UPDATED: Version bump for onboarding
)

# Enable CORS for React frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", 
                   "http://127.0.0.1:3000",
                   "https://deepcoach.vercel.app",
                   "https://*.vercel.app"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(toc_router)
app.include_router(module_router)
app.include_router(concept_router)
app.include_router(onboarding_router)  # NEW: Added onboarding router

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Learning Platform API v4.1",  # UPDATED: Version
        "features": [
            "Modular TOC generation",
            "Domain-specific prompts", 
            "Structured LLM output",
            "Learning path management",
            "Module generation with navigation",
            "Concept-level content generation",
            "Tabbed content interface",
            "Coach sidebar with concept tracking",
            "Generic onboarding with LLM question generation"  # NEW: Added onboarding feature
        ]
    }

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    
    # Check if OpenRouter API key is configured
    api_key = os.getenv("OPENROUTER_API_KEY")
    api_configured = bool(api_key and api_key != "your-key-here")
    
    return {
        "status": "healthy",
        "version": "4.1.0",  # UPDATED: Version
        "api_configured": api_configured,
        "features": {
            "toc_generation": True,
            "learning_path_management": True,
            "structured_output": True,
            "domain_prompts": True,
            "module_generation": True,
            "concept_generation": True,
            "content_blocks": True,
            "notes_generation": True,
            "navigation_system": True,
            "coach_sidebar": True,
            "tabbed_interface": True,
            "generic_onboarding": True,  # NEW: Added generic onboarding
            "question_generation": True  # NEW: Added question generation
        }
    }

@app.get("/api/domains")
async def get_supported_domains():
    """Get list of supported domains"""
    return {
        "success": True,
        "data": {
            "supported_domains": [
                {
                    "id": "generic",  # NEW: Added generic domain
                    "name": "Any Topic",
                    "description": "AI-generated curriculum for any learning topic",
                    "status": "active",
                    "features": {
                        "toc_generation": True,
                        "module_generation": True,
                        "concept_generation": True,
                        "content_generation": True,
                        "notes_generation": True,
                        "question_generation": True,  # NEW: Added question generation
                        "navigation_hierarchy": ["topic", "module", "concept"],
                        "evaluation_types": ["coding_exercise", "quiz", "mixed"],
                        "content_types": ["markdown_lessons", "code_examples", "interactive_exercises"]
                    }
                },
                {
                    "id": "data_science",
                    "name": "Data Science",
                    "description": "Comprehensive data science curriculum with ML, statistics, and programming",
                    "status": "active",
                    "features": {
                        "toc_generation": True,
                        "module_generation": True,
                        "concept_generation": True,
                        "content_generation": True,
                        "notes_generation": True,
                        "navigation_hierarchy": ["topic", "module", "concept"],
                        "evaluation_types": ["coding_exercise", "quiz", "mixed"],
                        "content_types": ["markdown_lessons", "code_examples", "interactive_exercises"]
                    }
                }
            ],
            "coming_soon": [
                {
                    "id": "cat_exam", 
                    "name": "CAT Exam Preparation",
                    "description": "Quantitative Aptitude, Verbal Ability, and Logical Reasoning",
                    "status": "development",
                    "features": {
                        "toc_generation": "planned",
                        "module_generation": "planned",
                        "concept_generation": "planned",
                        "navigation_hierarchy": ["topic", "module", "concept", "sub_concept"],
                        "evaluation_types": ["mcq", "timed_test"]
                    }
                }
            ]
        },
        "message": "Supported domains retrieved successfully"
    }

# Global exception handler
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Global exception: {str(exc)}")
    return HTTPException(
        status_code=500,
        detail=f"Internal server error: {str(exc)}"
    )

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(
        "main:app",  # Import string instead of app object
        host="0.0.0.0", 
        port=port, 
        log_level="info",
        reload=True  # Enable auto-reload during development
    )
----------------------------------------
File: ./content_generator.py
----------------------------------------
from typing import List, Dict
import uuid
from models import *
from backend.services.llm_service import LLMService
from prompts import *

class ContentGenerator:
    def __init__(self):
        self.llm = LLMService()
    
    def generate_course_structure(self, preferences: UserPreferences) -> Dict:
        """Generate complete course structure"""
        prompt = COURSE_STRUCTURE_PROMPT.format(
            topic=preferences.topic,
            level=preferences.learner_level,
            style=preferences.course_style,
            total_hours=preferences.total_hours,
            daily_minutes=preferences.daily_minutes
        )
        
        structure = self.llm.generate_json(
            "You are an expert curriculum designer for data science.",
            prompt
        )
        
        # Calculate number of sessions
        total_minutes = preferences.total_hours * 60
        sessions = total_minutes // preferences.daily_minutes
        
        print(f"Generated course with {len(structure['modules'])} modules for {sessions} sessions")
        return structure
    
    def generate_module_content(self, module: Dict, preferences: UserPreferences) -> Module:
        """Generate content for a single module"""
        # Calculate theory vs code percentages
        style_map = {
            CourseStyle.HANDS_ON: (20, 80),
            CourseStyle.BALANCED: (40, 60),
            CourseStyle.CONCEPT: (60, 40)
        }
        theory_percent, code_percent = style_map[preferences.course_style]
        
        prompt = MODULE_CONTENT_PROMPT.format(
            style=preferences.course_style,
            module_title=module['title'],
            topics=", ".join(module.get('topics', [])),
            objectives=", ".join(module.get('learning_objectives', [])),
            duration=module['estimated_minutes'],
            level=preferences.learner_level,
            theory_percent=theory_percent,
            code_percent=code_percent
        )
        
        content = self.llm.generate(
            "You are an expert data science instructor.",
            prompt
        )
        
        # Generate exercises for the module
        exercises = self.generate_exercises(
            module['title'], 
            preferences.learner_level
        )
        
        return Module(
            id=module['id'],
            title=module['title'],
            content=content,
            exercises=exercises,
            estimated_minutes=module['estimated_minutes'],
            order=module.get('order', 0)
        )
    
    def generate_exercises(self, topic: str, level: str, count: int = 2) -> List[Dict]:
        """Generate exercises for a topic"""
        exercises = []
        difficulty_map = {
            LearnerLevel.BEGINNER: ["easy", "easy"],
            LearnerLevel.INTERMEDIATE: ["easy", "medium"],
            LearnerLevel.ADVANCED: ["medium", "hard"]
        }
        
        for difficulty in difficulty_map.get(level, ["easy", "medium"]):
            prompt = EXERCISE_GENERATOR_PROMPT.format(
                topic=topic,
                difficulty=difficulty,
                focus_area="practical application"
            )
            
            exercise = self.llm.generate_json(
                "You are a coding exercise designer.",
                prompt
            )
            exercise['id'] = str(uuid.uuid4())[:8]
            exercises.append(exercise)
        
        return exercises
    
    def regenerate_exercise(self, topic: str, difficulty: str) -> Dict:
        """Generate a new exercise variant"""
        prompt = EXERCISE_GENERATOR_PROMPT.format(
            topic=topic,
            difficulty=difficulty,
            focus_area="different approach"
        )
        
        exercise = self.llm.generate_json(
            "Generate a NEW, different exercise. Don't repeat previous patterns.",
            prompt
        )
        exercise['id'] = str(uuid.uuid4())[:8]
        return exercise
----------------------------------------
File: ./llm_repo_digest.sh
----------------------------------------
#!/bin/bash

# Get repository name and set up output file
REPO_NAME=$(basename "$PWD")
OUTPUT_FILE="${REPO_NAME}_repo_digest.txt"

# Define source code file extensions we want to include
SOURCE_EXTENSIONS="\.(py|ipynb|js|jsx|ts|tsx|vue|java|cpp|hpp|c|h|go|rs|rb|php|cs|scala|kt|swift|m|mm|sh|bash|pl|pm|t|less|html|xml|sql|graphql|md|rst|tex|yaml|yml|json|coffee|dart|r|jl|lua|clj|cljs|ex|exs)$"

# Define common patterns to exclude
EXCLUDE_PATTERNS=(
    # Version control
    ".git"
    "__pycache__"
    
    # Data and binary files
    "*.csv"
    "*.xlsx"
    "*.json"
    "*.log"
    
    # Build and environment
    "node_modules"
    "docker"
    "venv"
    ".env"
    
    # IDE and editor files
    ".vscode"
    ".idea"
    "*.swp"
)

# Helper function to check if a file is binary
is_binary() {
    [ ! -f "$1" ] && return 1
    local mime
    mime=$(file -b --mime "$1")
    case "$mime" in
        *binary*) return 0 ;;
        *charset=binary*) return 0 ;;
        *) return 1 ;;
    esac
}

# Build exclude arguments for find command
build_find_excludes() {
    local excludes=()
    
    # Process predefined exclude patterns
    for pat in "${EXCLUDE_PATTERNS[@]}"; do
        if [[ "$pat" == *[*?]* ]]; then
            # Pattern contains wildcards - use -name
            excludes+=("-name" "$pat" "-prune" "-o")
        else
            # No wildcards - use -path
            excludes+=("-path" "./$pat" "-prune" "-o")
        fi
    done
    
    # Add patterns from .gitignore if it exists
    if [ -f .gitignore ]; then
        while IFS= read -r pattern; do
            # Skip comments and empty lines
            [[ "$pattern" =~ ^#.*$ || -z "$pattern" ]] && continue
            
            # Clean up pattern: remove trailing and leading slashes
            pattern="${pattern%/}"
            pattern="${pattern#/}"
            [[ -n "$pattern" ]] || continue
            
            # Handle wildcards in gitignore patterns
            if [[ "$pattern" == *[*?]* ]]; then
                excludes+=("-name" "$pattern" "-prune" "-o")
            else
                excludes+=("-path" "./$pattern" "-prune" "-o")
            fi
        done < .gitignore
    fi
    
    printf '%s\n' "${excludes[@]}"
}

# Initialize output file
> "$OUTPUT_FILE"
echo "Repository Source Code Contents" >> "$OUTPUT_FILE"
echo "Generated on: $(date)" >> "$OUTPUT_FILE"
echo "----------------------------------------" >> "$OUTPUT_FILE"

# Initialize counters
total_files=0
included_files=0
excluded_binary=0

echo "Building find command..." >&2

# Build the find command with excludes
mapfile -t FIND_EXCLUDES < <(build_find_excludes)

# Process files using find with proper array expansion
while IFS= read -r -d $'\0' path; do
    ((total_files++))
    echo "Processing: $path"
    
    if [[ "$path" =~ $SOURCE_EXTENSIONS ]]; then
        if ! is_binary "$path"; then
            echo "File: $path" >> "$OUTPUT_FILE"
            echo "----------------------------------------" >> "$OUTPUT_FILE"
            cat "$path" >> "$OUTPUT_FILE"
            echo -e "\n----------------------------------------" >> "$OUTPUT_FILE"
            ((included_files++))
        else
            echo "Skipping binary: $path"
            ((excluded_binary++))
        fi
    else
        echo "Skipping non-source file: $path"
    fi
done < <(find . "${FIND_EXCLUDES[@]}" -type f -print0)

# Print summary
echo -e "\nSummary:"
echo "Total files found: $total_files"
echo "Included in output: $included_files"
echo "Skipped binary files: $excluded_binary"
echo "Output: $OUTPUT_FILE"
----------------------------------------
File: ./services/learning_path_service.py
----------------------------------------
# ============================================================================
# File: services/learning_path_service.py (ENHANCED)
# Enhanced service to manage learning paths with concept storage
# ============================================================================

from typing import Dict, List, Any, Optional, Tuple
from models.toc_models import LearningPath, TableOfContents, Topic
from models.module_models import TopicWithModules, Module
from models.concept_models import ModuleWithConcepts, Concept, ConceptStatus
import uuid
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class LearningPathService:
    def __init__(self):
        # In-memory storage for learning paths and TOCs
        self.learning_paths: Dict[str, LearningPath] = {}
        self.tocs: Dict[str, TableOfContents] = {}
        self.topic_modules: Dict[str, Dict[str, TopicWithModules]] = {}  # session_id -> {topic_id: TopicWithModules}
        self.module_concepts: Dict[str, Dict[str, ModuleWithConcepts]] = {}  # session_id -> {module_id: ModuleWithConcepts}
        self.user_sessions: Dict[str, List[str]] = {}  # user_id -> list of session_ids
        self.current_selections: Dict[str, Dict[str, str]] = {}  # session_id -> {current_topic_id, current_module_id, current_concept_id}
    
    def store_toc(self, session_id: str, toc: TableOfContents) -> None:
        """Store generated TOC for a session"""
        self.tocs[session_id] = toc
        logger.info(f"Stored TOC for session {session_id} with {len(toc.topics)} topics")
    
    def get_toc(self, session_id: str) -> Optional[TableOfContents]:
        """Retrieve TOC for a session"""
        return self.tocs.get(session_id)
    
    def create_learning_path(self, 
                           user_id: str,
                           session_id: str,
                           selected_topic_ids: List[str],
                           user_preferences: Optional[Dict[str, Any]] = None) -> LearningPath:
        """Create a learning path from selected topics"""
        
        # Get the TOC for this session
        toc = self.get_toc(session_id)
        if not toc:
            raise ValueError(f"No TOC found for session {session_id}")
        
        # Validate selected topics exist in TOC
        toc_topic_ids = {topic.id for topic in toc.topics}
        invalid_topics = set(selected_topic_ids) - toc_topic_ids
        if invalid_topics:
            raise ValueError(f"Invalid topic IDs: {invalid_topics}")
        
        # Calculate total estimated hours for selected topics
        selected_topics = [topic for topic in toc.topics if topic.id in selected_topic_ids]
        total_hours = sum(topic.estimated_hours for topic in selected_topics)
        
        # Create learning path
        learning_path = LearningPath(
            user_id=user_id,
            session_id=session_id,
            domain=toc.domain,
            selected_topics=selected_topic_ids,
            estimated_total_hours=total_hours,
            created_at=datetime.now().isoformat(),
            user_preferences=user_preferences
        )
        
        # Store learning path
        self.learning_paths[session_id] = learning_path
        
        # Initialize module storage for this session
        self.topic_modules[session_id] = {}
        
        # Initialize concept storage for this session
        self.module_concepts[session_id] = {}
        
        # Initialize current selections (first topic, no module/concept selected yet)
        if selected_topic_ids:
            self.current_selections[session_id] = {
                "current_topic_id": selected_topic_ids[0],
                "current_module_id": None,
                "current_concept_id": None
            }
        
        # Track user sessions
        if user_id not in self.user_sessions:
            self.user_sessions[user_id] = []
        self.user_sessions[user_id].append(session_id)
        
        logger.info(f"Created learning path for user {user_id}, session {session_id}")
        logger.info(f"Selected {len(selected_topic_ids)} topics, estimated {total_hours:.1f} hours")
        
        return learning_path
    
    def store_topic_modules(self, session_id: str, topic_with_modules: TopicWithModules) -> None:
        """Store generated modules for a topic"""
        if session_id not in self.topic_modules:
            self.topic_modules[session_id] = {}
        
        self.topic_modules[session_id][topic_with_modules.topic_id] = topic_with_modules
        
        logger.info(f"Stored {len(topic_with_modules.modules)} modules for topic {topic_with_modules.topic_id}")
    
    def get_topic_modules(self, session_id: str, topic_id: str) -> Optional[TopicWithModules]:
        """Get modules for a specific topic"""
        return self.topic_modules.get(session_id, {}).get(topic_id)
    
    def get_all_session_modules(self, session_id: str) -> Dict[str, TopicWithModules]:
        """Get all generated modules for a session"""
        return self.topic_modules.get(session_id, {})
    
    def get_module_data(self, session_id: str, module_id: str) -> Optional[Dict[str, Any]]:
        """Get module data by module ID"""
        session_modules = self.topic_modules.get(session_id, {})
        
        for topic_modules in session_modules.values():
            for module in topic_modules.modules:
                if module.id == module_id:
                    return {
                        "id": module.id,
                        "name": module.name,
                        "description": module.description,
                        "estimated_hours": module.estimated_hours,
                        "learning_objectives": module.learning_objectives,
                        "evaluation_type": module.evaluation_type,
                        "topic_id": module.topic_id
                    }
        return None
    
    # NEW CONCEPT MANAGEMENT METHODS
    
    def store_module_concepts(self, session_id: str, module_with_concepts: ModuleWithConcepts) -> None:
        """Store generated concepts for a module"""
        if session_id not in self.module_concepts:
            self.module_concepts[session_id] = {}
        
        self.module_concepts[session_id][module_with_concepts.module_id] = module_with_concepts
        
        logger.info(f"Stored {len(module_with_concepts.concepts)} concepts for module {module_with_concepts.module_id}")
    
    def get_module_concepts(self, session_id: str, module_id: str) -> Optional[ModuleWithConcepts]:
        """Get concepts for a specific module"""
        return self.module_concepts.get(session_id, {}).get(module_id)
    
    def get_concept_data(self, session_id: str, concept_id: str) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]]]:
        """Get concept data and its parent module data by concept ID"""
        session_concepts = self.module_concepts.get(session_id, {})
        
        for module_id, module_with_concepts in session_concepts.items():
            for concept in module_with_concepts.concepts:
                if concept.id == concept_id:
                    concept_data = concept.dict()
                    module_data = {
                        "id": module_with_concepts.module_id,
                        "name": module_with_concepts.module_name,
                        "description": module_with_concepts.module_description,
                        "topic_id": module_with_concepts.topic_id
                    }
                    return concept_data, module_data
        return None, None
    
    def store_concept_content(self, session_id: str, concept: Concept) -> None:
        """Store generated content for a concept"""
        session_concepts = self.module_concepts.get(session_id, {})
        
        for module_with_concepts in session_concepts.values():
            for i, stored_concept in enumerate(module_with_concepts.concepts):
                if stored_concept.id == concept.id:
                    # Update the concept with new content
                    module_with_concepts.concepts[i] = concept
                    logger.info(f"Stored content for concept {concept.id}")
                    return
        
        logger.warning(f"Concept {concept.id} not found for content storage")
    
    def store_concept_notes(self, session_id: str, concept_id: str, notes_content: str) -> None:
        """Store generated notes for a concept"""
        session_concepts = self.module_concepts.get(session_id, {})
        
        for module_with_concepts in session_concepts.values():
            for concept in module_with_concepts.concepts:
                if concept.id == concept_id:
                    concept.notes_summary = notes_content
                    logger.info(f"Stored notes for concept {concept_id}")
                    return
        
        logger.warning(f"Concept {concept_id} not found for notes storage")
    
    def update_concept_progress(self, session_id: str, concept_id: str, status: str) -> None:
        """Update progress status for a concept"""
        session_concepts = self.module_concepts.get(session_id, {})
        
        for module_with_concepts in session_concepts.values():
            for concept in module_with_concepts.concepts:
                if concept.id == concept_id:
                    concept.status = ConceptStatus(status)
                    logger.info(f"Updated concept {concept_id} progress to {status}")
                    return
        
        logger.warning(f"Concept {concept_id} not found for progress update")
    
    def set_current_selection(self, session_id: str, topic_id: str, module_id: Optional[str] = None, concept_id: Optional[str] = None) -> None:
        """Set the current topic, module, and concept selection"""
        if session_id not in self.current_selections:
            self.current_selections[session_id] = {}
        
        self.current_selections[session_id]["current_topic_id"] = topic_id
        self.current_selections[session_id]["current_module_id"] = module_id
        self.current_selections[session_id]["current_concept_id"] = concept_id
        
        logger.info(f"Updated selection for session {session_id}: topic={topic_id}, module={module_id}, concept={concept_id}")
    
    def get_current_selection(self, session_id: str) -> Dict[str, Optional[str]]:
        """Get current topic, module, and concept selection"""
        return self.current_selections.get(session_id, {
            "current_topic_id": None,
            "current_module_id": None,
            "current_concept_id": None
        })
    
    def get_learning_path_with_concepts(self, session_id: str) -> Optional[Dict[str, Any]]:
        """Get complete learning path data including generated concepts"""
        learning_path = self.get_learning_path(session_id)
        if not learning_path:
            return None
        
        toc = self.get_toc(session_id)
        all_modules = self.get_all_session_modules(session_id)
        all_concepts = self.module_concepts.get(session_id, {})
        current_selection = self.get_current_selection(session_id)
        
        # Build navigation structure with concepts
        navigation_data = []
        
        if toc:
            for topic_id in learning_path.selected_topics:
                # Find topic in TOC
                topic_data = None
                for topic in toc.topics:
                    if topic.id == topic_id:
                        topic_data = topic
                        break
                
                if not topic_data:
                    continue
                
                # Get modules for this topic
                topic_modules = all_modules.get(topic_id)
                
                navigation_item = {
                    "topic_id": topic_id,
                    "topic_name": topic_data.name,
                    "topic_description": topic_data.description,
                    "topic_estimated_hours": topic_data.estimated_hours,
                    "modules": [],
                    "modules_generated": topic_modules is not None,
                    "is_current_topic": topic_id == current_selection.get("current_topic_id")
                }
                
                if topic_modules:
                    for module in topic_modules.modules:
                        # Get concepts for this module
                        module_concepts = all_concepts.get(module.id)
                        
                        module_item = {
                            "module_id": module.id,
                            "module_name": module.name,
                            "module_description": module.description,
                            "estimated_hours": module.estimated_hours,
                            "evaluation_type": module.evaluation_type,
                            "order": module.order,
                            "is_current_module": module.id == current_selection.get("current_module_id"),
                            "concepts": [],
                            "concepts_generated": module_concepts is not None
                        }
                        
                        # Add concepts if this is the current module
                        if module.id == current_selection.get("current_module_id") and module_concepts:
                            for concept in module_concepts.concepts:
                                concept_item = {
                                    "concept_id": concept.id,
                                    "concept_name": concept.name,
                                    "concept_description": concept.description,
                                    "estimated_minutes": concept.estimated_minutes,
                                    "order": concept.order,
                                    "status": concept.status,
                                    "is_current_concept": concept.id == current_selection.get("current_concept_id")
                                }
                                module_item["concepts"].append(concept_item)
                        
                        navigation_item["modules"].append(module_item)
                
                navigation_data.append(navigation_item)
        
        return {
            "learning_path": learning_path.dict(),
            "navigation": navigation_data,
            "current_selection": current_selection,
            "total_topics": len(learning_path.selected_topics),
            "topics_with_modules": len(all_modules),
            "modules_with_concepts": len(all_concepts)
        }
    
    def get_learning_path(self, session_id: str) -> Optional[LearningPath]:
        """Get learning path by session ID"""
        return self.learning_paths.get(session_id)
    
    def get_user_learning_paths(self, user_id: str) -> List[LearningPath]:
        """Get all learning paths for a user"""
        session_ids = self.user_sessions.get(user_id, [])
        return [self.learning_paths[sid] for sid in session_ids if sid in self.learning_paths]
    
    def update_learning_path(self, 
                           session_id: str, 
                           selected_topic_ids: List[str]) -> LearningPath:
        """Update an existing learning path with new topic selection"""
        learning_path = self.get_learning_path(session_id)
        if not learning_path:
            raise ValueError(f"No learning path found for session {session_id}")
        
        # Get TOC and validate topics
        toc = self.get_toc(session_id)
        if not toc:
            raise ValueError(f"No TOC found for session {session_id}")
        
        toc_topic_ids = {topic.id for topic in toc.topics}
        invalid_topics = set(selected_topic_ids) - toc_topic_ids
        if invalid_topics:
            raise ValueError(f"Invalid topic IDs: {invalid_topics}")
        
        # Clear modules and concepts for removed topics
        old_topics = set(learning_path.selected_topics)
        new_topics = set(selected_topic_ids)
        removed_topics = old_topics - new_topics
        
        if session_id in self.topic_modules:
            for topic_id in removed_topics:
                if topic_id in self.topic_modules[session_id]:
                    # Clear concepts for removed modules
                    topic_modules = self.topic_modules[session_id][topic_id]
                    for module in topic_modules.modules:
                        if session_id in self.module_concepts and module.id in self.module_concepts[session_id]:
                            del self.module_concepts[session_id][module.id]
                            logger.info(f"Removed concepts for module {module.id}")
                    
                    del self.topic_modules[session_id][topic_id]
                    logger.info(f"Removed modules for topic {topic_id}")
        
        # Recalculate total hours
        selected_topics = [topic for topic in toc.topics if topic.id in selected_topic_ids]
        total_hours = sum(topic.estimated_hours for topic in selected_topics)
        
        # Update learning path
        learning_path.selected_topics = selected_topic_ids
        learning_path.estimated_total_hours = total_hours
        
        # Update current selection if needed
        current_topic = self.current_selections.get(session_id, {}).get("current_topic_id")
        if current_topic not in selected_topic_ids:
            # Reset to first topic if current topic was removed
            if selected_topic_ids:
                self.set_current_selection(session_id, selected_topic_ids[0])
            else:
                self.current_selections.pop(session_id, None)
        
        logger.info(f"Updated learning path for session {session_id}")
        logger.info(f"New selection: {len(selected_topic_ids)} topics, {total_hours:.1f} hours")
        
        return learning_path
    
    def get_topic_details(self, session_id: str, topic_id: str) -> Optional[Dict[str, Any]]:
        """Get detailed information about a specific topic"""
        toc = self.get_toc(session_id)
        if not toc:
            return None
        
        for topic in toc.topics:
            if topic.id == topic_id:
                topic_modules = self.get_topic_modules(session_id, topic_id)
                
                return {
                    "topic": topic.dict(),
                    "modules": topic_modules.dict() if topic_modules else None,
                    "prerequisites": [
                        self._get_topic_by_id(toc, prereq_id) 
                        for prereq_id in topic.prerequisites
                    ],
                    "dependents": [
                        t.dict() for t in toc.topics 
                        if topic_id in t.prerequisites
                    ]
                }
        return None
    
    def _get_topic_by_id(self, toc: TableOfContents, topic_id: str) -> Optional[Dict[str, Any]]:
        """Helper to get topic by ID"""
        for topic in toc.topics:
            if topic.id == topic_id:
                return topic.dict()
        return None
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get service statistics"""
        total_modules = sum(
            len(topic_modules.modules) for session_modules in self.topic_modules.values()
            for topic_modules in session_modules.values()
        )
        
        total_concepts = sum(
            len(module_concepts.concepts) for session_concepts in self.module_concepts.values()
            for module_concepts in session_concepts.values()
        )
        
        return {
            "total_tocs": len(self.tocs),
            "total_learning_paths": len(self.learning_paths),
            "total_users": len(self.user_sessions),
            "total_generated_modules": total_modules,
            "total_generated_concepts": total_concepts,
            "average_topics_per_path": (
                sum(len(lp.selected_topics) for lp in self.learning_paths.values()) / 
                len(self.learning_paths) if self.learning_paths else 0
            )
        }

# Global service instance
learning_path_service = LearningPathService()
----------------------------------------
File: ./services/llm_service.py
----------------------------------------
# ============================================================================
# File: services/llm_service.py
# Enhanced LLM service with OpenRouter structured output support
# ============================================================================

import requests
import json
import os
from typing import Dict, Any, Optional, Type
from pydantic import BaseModel
from tenacity import retry, wait_exponential, stop_after_attempt
import logging

from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

class LLMService:
    def __init__(self, model: str = "openai/gpt-oss-20b:free"):
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY environment variable is required")
        
        self.base_url = "https://openrouter.ai/api/v1"
        self.model = model
        
    @retry(wait=wait_exponential(min=1, max=10), stop=stop_after_attempt(3))
    def generate(self, system_prompt: str, user_prompt: str, temperature: float = 0.7) -> str:
        """Basic LLM generation for unstructured output"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://learning-platform.com",
            "X-Title": "Learning Platform"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": temperature
        }
        
        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=payload
        )
        
        if response.status_code != 200:
            raise Exception(f"API request failed: {response.status_code} - {response.text}")
        
        result = response.json()
        return result["choices"][0]["message"]["content"]
    
    @retry(wait=wait_exponential(min=1, max=10), stop=stop_after_attempt(3))
    def generate_structured(self, 
                          system_prompt: str, 
                          user_prompt: str, 
                          response_model: Type[BaseModel],
                          temperature: float = 0.3) -> BaseModel:
        """Generate structured output using OpenRouter's JSON schema feature"""
        
        # Generate JSON schema from Pydantic model
        schema = response_model.model_json_schema()
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://learning-platform.com",
            "X-Title": "Learning Platform"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": temperature,
            "response_format": {
                "type": "json_schema",
                "json_schema": {
                    "name": response_model.__name__.lower(),
                    "strict": True,
                    "schema": schema
                }
            }
        }
        
        logger.info(f"Making structured request to {self.model}")
        logger.debug(f"Schema: {schema}")
        
        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=payload
        )
        
        if response.status_code != 200:
            raise Exception(f"Structured API request failed: {response.status_code} - {response.text}")
        
        result = response.json()
        content = result["choices"][0]["message"]["content"]
        
        # Parse and validate with Pydantic
        try:
            data = json.loads(content)
            return response_model(**data)
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse structured response: {content}")
            raise Exception(f"Failed to parse structured response: {e}")
    
    def set_model(self, model: str):
        """Switch models on the fly"""
        self.model = model
        logger.info(f"Switched to model: {model}")
----------------------------------------
